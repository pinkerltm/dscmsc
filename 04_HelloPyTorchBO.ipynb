{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=110x107 at 0x7FDDC41DAC50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "path = \"../BelgiumTS/Training/00056/00303_00000.ppm\"\n",
    "path = \"../BelgiumTS/Training/00056/00297_00002.ppm\"\n",
    "path = \"../BelgiumTS/Training/00056/01200_00000.ppm\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "rootdir = '/home/jzornig/devel/BelgiumTS/Training/'\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        print(os.path.join(subdir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "#model = models.vgg19(pretrained=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "\n",
    "bounds = np.array([[-1.0, 2.0]])\n",
    "noise = 0.2\n",
    "\n",
    "def f(X, noise=noise):\n",
    "    return -np.sin(3*X) - X**2 + 0.7*X + noise * np.random.randn(*X.shape)\n",
    "\n",
    "X_init = np.array([[-0.9], [1.1]])\n",
    "Y_init = f(X_init)\n",
    "\n",
    "kernel = GPy.kern.Matern52(input_dim=1, variance=1.0, lengthscale=1.0)\n",
    "bds = [{'name': 'X', 'type': 'continuous', 'domain': bounds.ravel()}]\n",
    "\n",
    "optimizer = BayesianOptimization(f=f, \n",
    "                                 domain=bds,\n",
    "                                 model_type='GP',\n",
    "                                 kernel=kernel,\n",
    "                                 acquisition_type ='EI',\n",
    "                                 acquisition_jitter = 0.01,\n",
    "                                 X=X_init,\n",
    "                                 Y=-Y_init,\n",
    "                                 noise_var = noise**2,\n",
    "                                 exact_feval=False,\n",
    "                                 normalize_Y=False,\n",
    "                                 maximize=True)\n",
    "\n",
    "optimizer.run_optimization(max_iter=10)\n",
    "optimizer.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds = [{'name': 'learning_rate', 'type': 'continuous', 'domain': (0, 1)},\n",
    "        {'name': 'max_epoch', 'type': 'discrete', 'domain': (1, 60)},\n",
    "        {'name': 'stepsize', 'type': 'discrete', 'domain': (20, 40)},\n",
    "        {'name': 'batchsize', 'type': 'discrete', 'domain': (10, 100)}]\n",
    "#lr 0.0003 --max-epoch 60 --stepsize 20 40 --train-batch 32 --test-batch 100\n",
    "\n",
    "# Optimization objective \n",
    "def cv_score(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = cross_val_score(\n",
    "                XGBRegressor(learning_rate=parameters[0],\n",
    "                              gamma=int(parameters[1]),\n",
    "                              max_depth=int(parameters[2]),\n",
    "                              n_estimators=int(parameters[3]),\n",
    "                              min_child_weight = parameters[4]), \n",
    "                X, Y, scoring='neg_mean_squared_error').mean()\n",
    "    score = np.array(score)\n",
    "    return score\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_score, \n",
    "                                 domain=bds,\n",
    "                                 model_type='GP',\n",
    "                                 acquisition_type ='EI',\n",
    "                                 acquisition_jitter = 0.05,\n",
    "                                 exact_feval=True, \n",
    "                                 maximize=True)\n",
    "\n",
    "# Only 20 iterations because we have 5 initial random points\n",
    "optimizer.run_optimization(max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2)\n",
       "    (3): Linear(in_features=512, out_features=80, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    #param.requires_grad = True # VGG19\n",
    "    param.requires_grad = False # ResNet50\n",
    "    \n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 #nn.Linear(512, 62),\n",
    "                                 nn.Linear(512, 80),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Train loss: 3.468.. Test loss: 2.800.. Test accuracy: 0.411\n",
      "Epoch 1/1.. Train loss: 2.471.. Test loss: 2.206.. Test accuracy: 0.486\n",
      "Epoch 1/1.. Train loss: 1.736.. Test loss: 1.634.. Test accuracy: 0.609\n",
      "Epoch 1/1.. Train loss: 1.487.. Test loss: 1.382.. Test accuracy: 0.635\n",
      "Epoch 1/1.. Train loss: 1.365.. Test loss: 1.160.. Test accuracy: 0.715\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "                \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "torch.save(model, 'HelloPyTorch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save \n",
    "torch.save(model.state_dict(), \"./HelloPyTorch_resnet50_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import *\n",
    "\n",
    "resnet_search_space = SearchSpace(\n",
    "    parameters=[\n",
    "        RangeParameter(\n",
    "            name=\"learning_rate\", parameter_type=ParameterType.FLOAT, lower=0, upper=1\n",
    "        ),\n",
    "        RangeParameter(\n",
    "            name=\"max_epoch\", parameter_type=ParameterType.INTEGER, lower=1, upper=30\n",
    "        ),\n",
    "        RangeParameter(\n",
    "            name=\"stepsize\", parameter_type=ParameterType.INTEGER, lower=20, upper=40\n",
    "        ),\n",
    "        RangeParameter(\n",
    "            name=\"batchsize\", parameter_type=ParameterType.INTEGER, lower=10, upper=100\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "exp = SimpleExperiment(\n",
    "    name=\"test_branin\",\n",
    "    search_space=resnet_search_space,\n",
    "    evaluation_function=lambda p: branin(p[\"x1\"], p[\"x2\"]),\n",
    "    objective_name=\"branin\",\n",
    "    minimize=True,\n",
    ")\n",
    "\n",
    "sobol = Models.SOBOL(exp.search_space)\n",
    "for i in range(5):\n",
    "    exp.new_trial(generator_run=sobol.gen(1))\n",
    "\n",
    "best_arm = None\n",
    "for i in range(15):\n",
    "    gpei = Models.GPEI(experiment=exp, data=exp.eval())\n",
    "    generator_run = gpei.gen(1)\n",
    "    best_arm, _ = generator_run.best_arm_predictions\n",
    "    exp.new_trial(generator_run=generator_run)\n",
    "\n",
    "best_parameters = best_arm.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize a Torch Model with Ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.2.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type='text/javascript'>/*\n",
       " * Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
       " */\n",
       "\n",
       "requirejs.config({\n",
       "  paths: {\n",
       "    plotly: ['https://cdn.plot.ly/plotly-latest.min'],\n",
       "  },\n",
       "});\n",
       "if (!window.Plotly) {\n",
       "  require(['plotly'], function(plotly) {\n",
       "    window.Plotly = plotly;\n",
       "  });\n",
       "}\n",
       "/*\n",
       " * Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
       " */\n",
       "\n",
       "// helper functions used across multiple plots\n",
       "function rgb(rgb_array) {\n",
       "  return 'rgb(' + rgb_array.join() + ')';\n",
       "}\n",
       "\n",
       "function copy_and_reverse(arr) {\n",
       "  const copy = arr.slice();\n",
       "  copy.reverse();\n",
       "  return copy;\n",
       "}\n",
       "\n",
       "function axis_range(grid, is_log) {\n",
       "  return is_log ?\n",
       "    [Math.log10(Math.min(...grid)), Math.log10(Math.max(...grid))]:\n",
       "    [Math.min(...grid), Math.max(...grid)];\n",
       "}\n",
       "\n",
       "function relativize_data(f, sd, rel, arm_data, metric) {\n",
       "  // if relative, extract status quo & compute ratio\n",
       "  const f_final = rel === true ? [] : f;\n",
       "  const sd_final = rel === true ? []: sd;\n",
       "\n",
       "  if (rel === true) {\n",
       "    const f_sq = (\n",
       "      arm_data['in_sample'][arm_data['status_quo_name']]['y'][metric]\n",
       "    );\n",
       "    const sd_sq = (\n",
       "      arm_data['in_sample'][arm_data['status_quo_name']]['se'][metric]\n",
       "    );\n",
       "\n",
       "    for (let i = 0; i < f.length; i++) {\n",
       "      res = relativize(f[i], sd[i], f_sq, sd_sq);\n",
       "      f_final.push(100 * res[0]);\n",
       "      sd_final.push(100 * res[1]);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  return [f_final, sd_final];\n",
       "}\n",
       "\n",
       "function relativize(m_t, sem_t, m_c, sem_c) {\n",
       "  r_hat = (\n",
       "    (m_t - m_c) / Math.abs(m_c) -\n",
       "    Math.pow(sem_c, 2) * m_t / Math.pow(Math.abs(m_c), 3)\n",
       "  );\n",
       "  variance = (\n",
       "    (Math.pow(sem_t, 2) + Math.pow((m_t / m_c * sem_c), 2)) /\n",
       "    Math.pow(m_c, 2)\n",
       "   )\n",
       "   return [r_hat, Math.sqrt(variance)];\n",
       "}\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-19 23:27:19] ipy_plotting: Injecting Plotly library into cell. Do not overwrite or delete cell.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from ax.utils.tutorials.cnn_utils import load_mnist, train, evaluate\n",
    "\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/jzornig/devel/BelgiumTS/Training/'\n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "    train_transforms = transforms.Compose([transforms.Resize((57,57)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "    test_transforms = transforms.Compose([transforms.Resize((57,57)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      ])\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=test_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=64)\n",
    "    return trainloader, testloader\n",
    "#trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "#print(trainloader.dataset.classes)\n",
    "#print(len(trainloader.dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = load_split_train_test(data_dir, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1280, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(parameterization):\n",
    "    #net = train(train_loader=train_loader, parameters=parameterization, dtype=dtype, device=device)\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "    #param.requires_grad = True # VGG19\n",
    "        param.requires_grad = False # ResNet50\n",
    "    \n",
    "    model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 #nn.Linear(512, 62),\n",
    "                                 nn.Linear(512, 80),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "    #criterion = nn.NLLLoss()\n",
    "    #optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "    return evaluate(\n",
    "        net=model,\n",
    "        data_loader=train_loader,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-20 06:41:20] ax.service.utils.dispatch: Using Bayesian Optimization generation strategy. Iterations after 5 will take longer to generate due to model-fitting.\n",
      "[INFO 05-20 06:41:20] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 05-20 06:41:20] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 05-20 06:41:56] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 05-20 06:42:34] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 05-20 06:43:09] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 05-20 06:43:45] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 05-20 06:44:24] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 05-20 06:45:06] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 05-20 06:45:45] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 05-20 06:46:27] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 05-20 06:47:06] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 05-20 06:47:47] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 05-20 06:48:26] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 05-20 06:49:06] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 05-20 06:49:48] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 05-20 06:50:29] ax.service.managed_loop: Running optimization trial 15...\n",
      "[INFO 05-20 06:51:12] ax.service.managed_loop: Running optimization trial 16...\n",
      "[INFO 05-20 06:51:52] ax.service.managed_loop: Running optimization trial 17...\n",
      "[INFO 05-20 06:52:34] ax.service.managed_loop: Running optimization trial 18...\n",
      "[INFO 05-20 06:53:18] ax.service.managed_loop: Running optimization trial 19...\n",
      "/home/jzornig/.conda/envs/dscmsc/lib/python3.6/site-packages/botorch/optim/optimize.py:237: BadInitialCandidatesWarning:\n",
      "\n",
      "Unable to find non-zero acquistion function values - initial conditions are being selected randomly.\n",
      "\n",
      "[INFO 05-20 06:54:00] ax.service.managed_loop: Running optimization trial 20...\n",
      "/home/jzornig/.conda/envs/dscmsc/lib/python3.6/site-packages/botorch/optim/optimize.py:237: BadInitialCandidatesWarning:\n",
      "\n",
      "Unable to find non-zero acquistion function values - initial conditions are being selected randomly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        #{\"name\": \"momentum\", \"type\": \"range\", \"bounds\": [0.0, 1.0]},\n",
    "        {\"name\": \"max_epoch\", \"type\": \"range\", \"bounds\": [1, 30]},\n",
    "        {\"name\": \"stepsize\", \"type\": \"range\", \"bounds\": [20, 40]},\n",
    "        {\"name\": \"batchsize\", \"type\": \"range\", \"bounds\": [10, 100]},\n",
    "        \n",
    "    ],\n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name='accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0015118706900009594, 'max_epoch': 2, 'stepsize': 40, 'batchsize': 35}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.07049180089915703},\n",
       " {'accuracy': {'accuracy': 8.80289009602516e-12}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, covariances = values\n",
    "means, covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"899c9fad5617455b94cc54fe88adfbe3\" style=\"width: 100%;\" class=\"plotly-graph-div\"></div><script type='text/javascript'>/*\n",
       " * Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
       " */\n",
       "\n",
       "require(['plotly'], function(Plotly) {\n",
       "  window.PLOTLYENV = window.PLOTLYENV || {};\n",
       "  window.PLOTLYENV.BASE_URL = 'https://plot.ly';\n",
       "  /*\n",
       " * Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
       " */\n",
       "\n",
       "const arm_data = {\"metrics\": [\"accuracy\"], \"in_sample\": {\"0_0\": {\"name\": \"0_0\", \"parameters\": {\"lr\": 0.003824593396211094, \"momentum\": 0.8759193420410156}, \"y\": {\"accuracy\": 0.11583333333333333}, \"y_hat\": {\"accuracy\": 0.11583333837269816}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981481313755789e-05}, \"context_stratum\": null}, \"1_0\": {\"name\": \"1_0\", \"parameters\": {\"lr\": 0.021202780844299652, \"momentum\": 0.05572724714875221}, \"y\": {\"accuracy\": 0.0935}, \"y_hat\": {\"accuracy\": 0.09350001170917335}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981481344759796e-05}, \"context_stratum\": null}, \"2_0\": {\"name\": \"2_0\", \"parameters\": {\"lr\": 1.1972851180627287e-06, \"momentum\": 0.5601797103881836}, \"y\": {\"accuracy\": 0.26}, \"y_hat\": {\"accuracy\": 0.26000000658249117}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981481298253786e-05}, \"context_stratum\": null}, \"3_0\": {\"name\": \"3_0\", \"parameters\": {\"lr\": 1.0985673564895968e-05, \"momentum\": 0.1979065239429474}, \"y\": {\"accuracy\": 0.6685}, \"y_hat\": {\"accuracy\": 0.6684998296441972}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981467361938618e-05}, \"context_stratum\": null}, \"4_0\": {\"name\": \"4_0\", \"parameters\": {\"lr\": 0.13012012040294885, \"momentum\": 0.7013218998908997}, \"y\": {\"accuracy\": 0.0885}, \"y_hat\": {\"accuracy\": 0.08850000238481176}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981481344759796e-05}, \"context_stratum\": null}, \"5_0\": {\"name\": \"5_0\", \"parameters\": {\"lr\": 3.8566389596328395e-06, \"momentum\": 0.056864892676805306}, \"y\": {\"accuracy\": 0.3496666666666667}, \"y_hat\": {\"accuracy\": 0.34966672844492525}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981480120101411e-05}, \"context_stratum\": null}, \"6_0\": {\"name\": \"6_0\", \"parameters\": {\"lr\": 1.7581917657100034e-05, \"momentum\": 0.2778356504372707}, \"y\": {\"accuracy\": 0.7331666666666666}, \"y_hat\": {\"accuracy\": 0.7331668169300535}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981464339041222e-05}, \"context_stratum\": null}, \"7_0\": {\"name\": \"7_0\", \"parameters\": {\"lr\": 5.372522269538952e-05, \"momentum\": 0.2349406478141892}, \"y\": {\"accuracy\": 0.8583333333333333}, \"y_hat\": {\"accuracy\": 0.8583332063623743}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981462757832833e-05}, \"context_stratum\": null}, \"8_0\": {\"name\": \"8_0\", \"parameters\": {\"lr\": 9.487273601702114e-05, \"momentum\": 0.1270221298671996}, \"y\": {\"accuracy\": 0.8903333333333333}, \"y_hat\": {\"accuracy\": 0.8903334818917777}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981453952665837e-05}, \"context_stratum\": null}, \"9_0\": {\"name\": \"9_0\", \"parameters\": {\"lr\": 5.806076999293828e-05, \"momentum\": 0.06608109905808866}, \"y\": {\"accuracy\": 0.8666666666666667}, \"y_hat\": {\"accuracy\": 0.8666666541270467}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981470911903631e-05}, \"context_stratum\": null}, \"10_0\": {\"name\": \"10_0\", \"parameters\": {\"lr\": 0.00017888465491378087, \"momentum\": 0.0}, \"y\": {\"accuracy\": 0.8943333333333333}, \"y_hat\": {\"accuracy\": 0.8943332272239526}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981458370752777e-05}, \"context_stratum\": null}, \"11_0\": {\"name\": \"11_0\", \"parameters\": {\"lr\": 0.0002272315199240098, \"momentum\": 0.09642699192584717}, \"y\": {\"accuracy\": 0.903}, \"y_hat\": {\"accuracy\": 0.9030001267879689}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981438884643033e-05}, \"context_stratum\": null}, \"12_0\": {\"name\": \"12_0\", \"parameters\": {\"lr\": 0.00020134470130439496, \"momentum\": 0.26958900203179714}, \"y\": {\"accuracy\": 0.9175}, \"y_hat\": {\"accuracy\": 0.9174997808171618}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981443070208186e-05}, \"context_stratum\": null}, \"13_0\": {\"name\": \"13_0\", \"parameters\": {\"lr\": 0.00012463152956353188, \"momentum\": 0.6722699286827456}, \"y\": {\"accuracy\": 0.9036666666666666}, \"y_hat\": {\"accuracy\": 0.9036662560114299}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981452588484041e-05}, \"context_stratum\": null}, \"14_0\": {\"name\": \"14_0\", \"parameters\": {\"lr\": 0.0001537476188078138, \"momentum\": 0.4493084941029494}, \"y\": {\"accuracy\": 0.8983333333333333}, \"y_hat\": {\"accuracy\": 0.8983335759139939}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981457797176736e-05}, \"context_stratum\": null}, \"15_0\": {\"name\": \"15_0\", \"parameters\": {\"lr\": 7.07969259975164e-05, \"momentum\": 0.9999999999999957}, \"y\": {\"accuracy\": 0.8681666666666666}, \"y_hat\": {\"accuracy\": 0.8681665410613807}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981477205723629e-05}, \"context_stratum\": null}, \"16_0\": {\"name\": \"16_0\", \"parameters\": {\"lr\": 0.00017811228056453769, \"momentum\": 1.0}, \"y\": {\"accuracy\": 0.5751666666666667}, \"y_hat\": {\"accuracy\": 0.5751668242413849}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981478910944819e-05}, \"context_stratum\": null}, \"17_0\": {\"name\": \"17_0\", \"parameters\": {\"lr\": 4.946953894812496e-05, \"momentum\": 0.7800387142067331}, \"y\": {\"accuracy\": 0.916}, \"y_hat\": {\"accuracy\": 0.9159999455468498}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.98146579623295e-05}, \"context_stratum\": null}, \"18_0\": {\"name\": \"18_0\", \"parameters\": {\"lr\": 7.797030773291157e-05, \"momentum\": 0.6932745157522857}, \"y\": {\"accuracy\": 0.903}, \"y_hat\": {\"accuracy\": 0.9030003126122735}, \"se\": {\"accuracy\": 0.0}, \"se_hat\": {\"accuracy\": 6.981436652340594e-05}, \"context_stratum\": null}}, \"out_of_sample\": {}, \"status_quo_name\": null};\n",
       "const density = 50;\n",
       "const grid_x = [1e-06, 1.3011511650442548e-06, 1.692994354296022e-06, 2.2028415765056147e-06, 2.866229883678204e-06, 3.729398352432554e-06, 4.852511011181743e-06, 6.3138503555892e-06, 8.215273746089953e-06, 1.0689313005882424e-05, 1.390841207112662e-05, 1.809694657026198e-05, 2.354686311364001e-05, 3.063802837345029e-05, 3.986470631277378e-05, 5.1870009063012666e-05, 6.749072272319499e-05, 8.781563250096393e-05, 0.00011426141253772724, 0.00014867137004306603, 0.00019344392634026088, 0.0002516997901283655, 0.0003274994751669172, 0.0004261263236648159, 0.0005544547624925005, 0.0007214294601814526, 0.000938688782612345, 0.0012213760031100258, 0.0015891948094037057, 0.002067782677737912, 0.0026904978401970136, 0.0035007443993213955, 0.004554997653699184, 0.005926740503884541, 0.007711585311544345, 0.010033938212454078, 0.013055670395116691, 0.01698740074503987, 0.02210317627048227, 0.028759573555516536, 0.03742055263793628, 0.04868979566145066, 0.06335278435066323, 0.0824315491666629, 0.10725590623460621, 0.13955614735503497, 0.18158364372009145, 0.23626776957937787, 0.3074200836506151, 0.4];\n",
       "const grid_y = [0.0, 0.02040816326530612, 0.04081632653061224, 0.061224489795918366, 0.08163265306122448, 0.1020408163265306, 0.12244897959183673, 0.14285714285714285, 0.16326530612244897, 0.18367346938775508, 0.2040816326530612, 0.22448979591836732, 0.24489795918367346, 0.26530612244897955, 0.2857142857142857, 0.3061224489795918, 0.32653061224489793, 0.3469387755102041, 0.36734693877551017, 0.3877551020408163, 0.4081632653061224, 0.42857142857142855, 0.44897959183673464, 0.4693877551020408, 0.4897959183673469, 0.5102040816326531, 0.5306122448979591, 0.5510204081632653, 0.5714285714285714, 0.5918367346938775, 0.6122448979591836, 0.6326530612244897, 0.6530612244897959, 0.673469387755102, 0.6938775510204082, 0.7142857142857142, 0.7346938775510203, 0.7551020408163265, 0.7755102040816326, 0.7959183673469387, 0.8163265306122448, 0.836734693877551, 0.8571428571428571, 0.8775510204081632, 0.8979591836734693, 0.9183673469387754, 0.9387755102040816, 0.9591836734693877, 0.9795918367346939, 1.0];\n",
       "const f = [0.08847979722492211, 0.11379711464815692, 0.1498923019903562, 0.19759066915340723, 0.25702032633686883, 0.3271447879472478, 0.4051339138115091, 0.4861128157568052, 0.5642683434575656, 0.6346081335449684, 0.6943179030875556, 0.7430664464956195, 0.7820872924027704, 0.8129083339427845, 0.8367539696127214, 0.8547697228449188, 0.8684736087610742, 0.8795809636575915, 0.8887349595420052, 0.8942915864757318, 0.893096693775105, 0.882851060043233, 0.8629750739662415, 0.8336117541887943, 0.7953931509845658, 0.7494394728280874, 0.6972097794194262, 0.6403204084528078, 0.5804028015445671, 0.519013484675254, 0.4575887001923424, 0.3974317924183704, 0.33972155428654927, 0.2855306468331273, 0.2358437769535303, 0.19156514842960368, 0.15350355998863163, 0.12232123518498701, 0.09842951731108979, 0.08183349531846706, 0.07207000742064143, 0.06835667659651279, 0.06976883818577398, 0.07535758772870746, 0.08422026458086632, 0.09553855006480697, 0.10859542788017018, 0.12277903861794782, 0.13757895118483382, 0.15257845316127405, 0.0896310006778874, 0.11544490692243725, 0.15211612262046553, 0.20046062321527994, 0.2605914876582881, 0.33145094502091876, 0.41015508612706647, 0.49167786729332275, 0.5700246489937946, 0.640092393366199, 0.6991294708442902, 0.7470599316544966, 0.785393237197901, 0.8157647124540092, 0.839320383255699, 0.857067247636437, 0.8704886530560727, 0.8814536430973804, 0.8907983100306923, 0.8968481314281681, 0.8962500539914782, 0.8865451675374302, 0.8670222373899868, 0.8377188590214896, 0.7992581197686419, 0.7528186824692099, 0.6999375378896827, 0.6423045318802224, 0.5816116972793658, 0.5194614618593997, 0.45732222205642803, 0.39651775444094706, 0.338237975326935, 0.2835598324956527, 0.2334678576328611, 0.18886382966185758, 0.15055390802568147, 0.1191993083679232, 0.09521302105316135, 0.07859713775306276, 0.06887266872606537, 0.06524140591316863, 0.0667668142561908, 0.0724913572245281, 0.08150608743061216, 0.09298795813199334, 0.1062161612056357, 0.12057555433454804, 0.13555269976326093, 0.15072808259173234, 0.09123680952057928, 0.11756657804846035, 0.15481807099571607, 0.20378908562554202, 0.26456555023410727, 0.3360532949544363, 0.4153090921378304, 0.4971777753440191, 0.5755146952726653, 0.6451251746484111, 0.7033369729022546, 0.7503587348564883, 0.7879950804942822, 0.8179776517831489, 0.8413429935772843, 0.858923795635412, 0.872141010320812, 0.8830110797013154, 0.8925791438502196, 0.8991486536704488, 0.8991746110538016, 0.8900360292232027, 0.8708660343711382, 0.8415978186374258, 0.8028651961237012, 0.7559187113901538, 0.7023786189707195, 0.6440092026464994, 0.5825621077789439, 0.5196839374658204, 0.45687323959206655, 0.3954721164129269, 0.336679433294499, 0.28157414060236163, 0.23113809883707587, 0.18626779595084814, 0.1477632994121998, 0.11628052224021537, 0.09222918218797171, 0.07560627721881871, 0.06592017506203263, 0.06236129336551233, 0.06398469981056087, 0.06982677353014721, 0.07897410441038474, 0.09060017696177436, 0.10398120857387527, 0.11849925025499727, 0.1336380809018796, 0.14897543136242933, 0.09329231634730054, 0.12015472590676754, 0.15798762889682735, 0.20756168851990067, 0.2689234060730379, 0.34092580881843265, 0.4205555355893634, 0.5025572732372667, 0.5806741737123187, 0.6496413888392294, 0.7068815867250335, 0.7529162338376608, 0.7898611965714483, 0.8195296425826774, 0.8428178937624722, 0.8603511281977086, 0.8734611481104411, 0.8843004786747078, 0.8941343783298336, 0.9012552198852228, 0.9019310144145355, 0.8933654420650998, 0.8745224246439693, 0.8452442458188592, 0.8061982187147325, 0.7587178975365046, 0.7045096511657583, 0.6454115003169283, 0.5832327768444989, 0.5196619862814097, 0.45622549755333225, 0.39428142814022593, 0.3350352911482748, 0.27956568056097153, 0.22884925227520225, 0.18377432650202363, 0.1451314302170028, 0.1135668551064496, 0.08948161124254975, 0.07286468806495477, 0.06321616478272724, 0.059719801249315335, 0.06142576963297783, 0.06736692192856461, 0.07662721656602928, 0.08837793406627845, 0.10189313679676917, 0.11655254363095302, 0.13183736896248394, 0.14732263237055074, 0.09578891061158773, 0.12319722090592049, 0.1616082258342922, 0.21175629565103052, 0.27363604282830883, 0.34603107488028323, 0.42584565712547806, 0.5077568173699344, 0.5854378261048827, 0.6535786049012496, 0.7097111205359947, 0.7546955455948946, 0.7909700255062051, 0.8204103203364619, 0.8437437409609942, 0.8613595020005888, 0.8744757763352645, 0.8853647697732703, 0.8955142625780452, 0.9032196535781937, 0.9045680297244885, 0.8965633220023674, 0.8779950334274125, 0.8486439539288202, 0.809234196159871, 0.7611900488997535, 0.7063042710397449, 0.6464864731435653, 0.5836009870248589, 0.5193755294506851, 0.455361708264437, 0.3929311835120584, 0.3332937086334108, 0.2775250955573763, 0.2265942244316603, 0.18137835476086656, 0.1426550240558499, 0.11105659207184462, 0.08696984693349155, 0.070372642441833, 0.06076144902998895, 0.05731813720106163, 0.05909151064644763, 0.06511347616708879, 0.07446721533448014, 0.08632308887021203, 0.09995383715632927, 0.11473732886806129, 0.13015243551027406, 0.14577150908131625, 0.09871450546442798, 0.12667752176132063, 0.1656576756918453, 0.21634358899204034, 0.2786652354775657, 0.35132061722707736, 0.4311240214380423, 0.5127151995022997, 0.5897423899875381, 0.6568801534727661, 0.7117835199710939, 0.7556731513143731, 0.7913130365837774, 0.8206182378649104, 0.8441220716121287, 0.8619564587348914, 0.8752044527758124, 0.8862374828283675, 0.8967550929252915, 0.9050735745165468, 0.9071106809992184, 0.8996379437581591, 0.8812702335076998, 0.8517710773197366, 0.811942761000787, 0.7633044062336811, 0.7077332499749517, 0.6472073009292537, 0.5836427170912979, 0.5188034757136805, 0.4542636751549099, 0.3914059270516872, 0.331441732640603, 0.2754416370039835, 0.22436413443454856, 0.1790725069541556, 0.14032784247519625, 0.10874427217106561, 0.08468918909779236, 0.06812687023322334, 0.05855400434160893, 0.055155257348652786, 0.05698162902363613, 0.0630667069599786, 0.07249479127401082, 0.08443664108793417, 0.09816453309964401, 0.11305498430846475, 0.12858475500124417, 0.14432357999768733, 0.1020538791150255, 0.1305751796377151, 0.17010894300236112, 0.2212882920795837, 0.2839657074717107, 0.3567393323543216, 0.4363322139441766, 0.5173732470763164, 0.593530421025469, 0.6594988859961133, 0.7130709422953041, 0.7558428694468344, 0.7908978151803059, 0.8201627870620827, 0.8439578905094262, 0.8621457066922968, 0.8756561475472149, 0.8869370608658598, 0.8978722545659996, 0.9068211701463973, 0.9095512194655695, 0.9025672915199469, 0.8843139661907929, 0.8545873018540298, 0.8142862561555917, 0.7650259500707535, 0.7087648066839531, 0.6475455609532231, 0.5833328608068546, 0.5179239035779957, 0.45291244833065847, 0.38968939049381196, 0.3294654209365809, 0.27330328164327067, 0.22214843289624864, 0.17684723732235919, 0.13814087015950938, 0.10662103161729594, 0.08263130183598333, 0.06612081371064427, 0.05658910564263983, 0.05322794885980173, 0.055094106429407486, 0.0612255225657706, 0.07070956447268906, 0.08271875409740992, 0.09652579846613218, 0.11150638646741548, 0.12713541574675397, 0.1429800668415732, 0.10578911705883001, 0.13486650578756743, 0.17493118787487777, 0.22655089986973317, 0.28948823483948694, 0.36223057243157974, 0.4414136278743005, 0.5216783425622054, 0.5967549687395861, 0.6614016027988006, 0.7135643642527534, 0.7552199543353056, 0.7897510249582201, 0.8190661768413002, 0.8432607043713867, 0.8619267592094603, 0.8758270192678521, 0.8874610838593601, 0.8988551375629568, 0.9084362680490207, 0.9118464046629643, 0.9052966260491631, 0.8870715451956083, 0.8570425630945936, 0.8162205550029465, 0.7663160730832576, 0.7093651043605936, 0.6474715917232073, 0.58264550237394, 0.5167142811156533, 0.4512885098544308, 0.38776465758136425, 0.32734999752593535, 0.2710968890666282, 0.21993507784041824, 0.17469105104448884, 0.1360826454168559, 0.10467517714041052, 0.08078495813022823, 0.06434508741367959, 0.05485958039343447, 0.0515309854498584, 0.05342530260652542, 0.05958754001626507, 0.06911013581909656, 0.08116879279784586, 0.09503758589701725, 0.11009193146603277, 0.12580513595163345, 0.1417419062780792, 0.1099001346308249, 0.13952536327635995, 0.1800910043085494, 0.23208969305730773, 0.29518295472711537, 0.3677405012388141, 0.4463182167949654, 0.5255892635688897, 0.5993849658563947, 0.6625741597058888, 0.7132786156876001, 0.7538449282155493, 0.7879208879880008, 0.8173653157538272, 0.8420461892406502, 0.8612961630410679, 0.8757011249645736, 0.8877838328808048, 0.8996668368299988, 0.9098645938220559, 0.9139223479072659, 0.9077443920772565, 0.8894709005523992, 0.8590773323812387, 0.8176966212861021, 0.7671335974945828, 0.70949891301197, 0.6469549410792262, 0.5815542401274615, 0.5151517181631883, 0.4493719852553293, 0.385614354299755, 0.3250800366976069, 0.2688083954338445, 0.21771075996008848, 0.17259079704361352, 0.13413968379879312, 0.1028928071884122, 0.07913670740842729, 0.06278801931591477, 0.053356147971980794, 0.05005734277553406, 0.05197009852690737, 0.05814918407232961, 0.06769415750018254, 0.07978537496205426, 0.09369926478618024, 0.10881156321667382, 0.12459428449929993, 0.14060976493081284, 0.11436525421674068, 0.14452403365989802, 0.18555374859053897, 0.23786279696514204, 0.30100236982252865, 0.37322162471321463, 0.45100653947555136, 0.5290807021390813, 0.6014109479831439, 0.6630272781095436, 0.7122575220598109, 0.7517865304390143, 0.7854787219761373, 0.8151133728190371, 0.8403386082190588, 0.8602506704439727, 0.8752550570213431, 0.8878634931908134, 0.9002511375140021, 0.9110311091720402, 0.9156840636097761, 0.9098119436390028, 0.8914287282558437, 0.8606263253964349, 0.8186627062897216, 0.7674360730745334, 0.7091303992005347, 0.6459648774310796, 0.5800325466374611, 0.5132132440612939, 0.44714287680812415, 0.3832208609342361, 0.3226396717909607, 0.26642303760651626, 0.215461166748288, 0.17053200843705818, 0.13229694245269524, 0.10125839765795228, 0.07767146607410857, 0.06143618990022243, 0.052067804592653255, 0.048798456798898965, 0.05072207213816604, 0.05690580975772774, 0.06645842038390523, 0.07856643466867683, 0.09250966786465381, 0.10766480774375653, 0.1235029060405805, 0.1395840573560606, 0.1191618085838391, 0.14983410565704103, 0.19128485417074104, 0.24383008500416747, 0.306903808908367, 0.3786354512051311, 0.45545276007597507, 0.5321467713156122, 0.6028501962512255, 0.6628031259097431, 0.7105782364017216, 0.749142941661976, 0.782519010422073, 0.8123807127301632, 0.8381739339886531, 0.858792339403626, 0.8744660936295495, 0.8876554596332152, 0.9005450673011482, 0.9118513851318111, 0.9170272093301081, 0.9113944461973178, 0.8928584953660293, 0.8616232178995277, 0.8190669790117787, 0.767181251157435, 0.7082239896646628, 0.6444709366312042, 0.5780541507753355, 0.5108761028554728, 0.4445813133937413, 0.3805665416984941, 0.3200128239548934, 0.2639256008675732, 0.21317127375405004, 0.16849926840189028, 0.1305382859394047, 0.09975532995846084, 0.0763730381500253, 0.060274931713291124, 0.05098222014078649, 0.04774450740441141, 0.04967369754266748, 0.0558518434735171, 0.06539895539471402, 0.07750929604575382, 0.09146714527945021, 0.10665081286716208, 0.12253074983568818, 0.13866496656897384, 0.12426674131485534, 0.15542733477341572, 0.19725104315080064, 0.24995479014586994, 0.3128512599893505, 0.3839542614305585, 0.4596464306945237, 0.5348028806892451, 0.6037496525383124, 0.6619819066844911, 0.7083526394286416, 0.7460403412785404, 0.7791575057936234, 0.8092548553593012, 0.8356033513533208, 0.856935315818364, 0.8733223338289885, 0.8871253975020287, 0.9004930237300116, 0.9122454616295164, 0.9178511144252827, 0.9123925430207581, 0.8936792384047726, 0.8620057894115454, 0.8188603090495606, 0.766328600767374, 0.7067452444670453, 0.6424434730392504, 0.5755934258077461, 0.5081180572183727, 0.4416678113286464, 0.37763398727588815, 0.3171834457061089, 0.26130068292530084, 0.21082565125148103, 0.16647658230489584, 0.1288469294798275, 0.09836635946680769, 0.07522457251220249, 0.05928877740121494, 0.050086123201522115, 0.046884711143049984, 0.04881655823781053, 0.05498093725754555, 0.0645111456235423, 0.07661075529076655, 0.0905696248395697, 0.1057683923425845, 0.12167730170397946, 0.13785246664745343, 0.1296571770476016, 0.16127642933165845, 0.20342136629649837, 0.2562047491269287, 0.3188165688885737, 0.3891620049522181, 0.46359300401720094, 0.537085609708565, 0.6041848688160072, 0.6606806314544098, 0.7057230646759408, 0.7426280332401644, 0.775527038489218, 0.8058391492997065, 0.8326963454015726, 0.8547139388044265, 0.8718327499256673, 0.886260120698382, 0.9000597760651753, 0.9121525461743083, 0.9180727396895891, 0.9127245757664535, 0.8938241761420379, 0.8617208435214954, 0.817998884249321, 0.7648407194545468, 0.7046616712790504, 0.6398541823665674, 0.5726257674354076, 0.5049176923274203, 0.4383835404640331, 0.37440626545404426, 0.3141357739225178, 0.2585329669467641, 0.20840877564485188, 0.16444774137351464, 0.12720584723264605, 0.09707402766110079, 0.07420896253748183, 0.058461854783541295, 0.04936565983561761, 0.04620760992504119, 0.048141565637448785, 0.054286130704203184, 0.06378984573592614, 0.07586716876015326, 0.0898146769632032, 0.10501607344650338, 0.12094181835584131, 0.13714634688081842, 0.13531093769464916, 0.16735572781187527, 0.20976802760647195, 0.2625532525550096, 0.3247800374536476, 0.3942543835145182, 0.46731314755793774, 0.5390506043250826, 0.6042547713992252, 0.6590407196499792, 0.7028518155265631, 0.7390698387680232, 0.7717711120288122, 0.8022500308994592, 0.8295420647445599, 0.8521905565776547, 0.8700345581868231, 0.8850753117381002, 0.8992408136447663, 0.9115447995385805, 0.9176413272458127, 0.9123387386599705, 0.8932481068776107, 0.8607282615238715, 0.8164463513782995, 0.7626844965561786, 0.7019434161051256, 0.636676566201355, 0.5691279469777006, 0.5012547115580552, 0.43471059010776125, 0.37086717511346423, 0.310854587010556, 0.25560749682803074, 0.20590533655922175, 0.16239666762887628, 0.12559814047895182, 0.09586102229911306, 0.0733091933904394, 0.05777823131327364, 0.04880671854516505, 0.04570134583142707, 0.04763917521854705, 0.053760015333222416, 0.06322950523833445, 0.07527454484249976, 0.08919958277168219, 0.10439214691463822, 0.12032336331672012, 0.13654623688169154, 0.14120698546357668, 0.1736417431322414, 0.21626697198983208, 0.2689795086815162, 0.33073048203648947, 0.3992382240977189, 0.4708410476207274, 0.5407689247822733, 0.6040739558520916, 0.6572146847301429, 0.699907390271715, 0.7355319945511228, 0.7680361038898724, 0.798613060755234, 0.8262477901667254, 0.849456039940546, 0.8679954584299936, 0.883619353483348, 0.8980689345199444, 0.9104379826130602, 0.9165533932638646, 0.9112233463014424, 0.8919324614869405, 0.8590036314861699, 0.8141752174446362, 0.75983191020826, 0.6985637770924537, 0.6328863136142326, 0.5650784275466322, 0.4971102170889876, 0.43063222988460415, 0.3670014991258137, 0.30732546131346694, 0.25250994865625936, 0.2033005324129544, 0.1603077335499401, 0.12400736462374666, 0.09471048998262471, 0.07250864163261472, 0.057222211438127946, 0.04839521834742014, 0.04535391532443531, 0.04729959402512232, 0.05339489670420389, 0.06282429230675565, 0.07482863733633022, 0.08872140373613696, 0.10389471809181536, 0.11982084360553547, 0.13605163204182388, 0.147325778718364, 0.180113560113991, 0.222898233417001, 0.27546875179628655, 0.3366648311264823, 0.4041302784193992, 0.47422197519408327, 0.5423225091956375, 0.6037646476220009, 0.655355327173366, 0.6970516948411856, 0.7321692075135694, 0.7644638006450329, 0.7950582672068317, 0.8229345716958697, 0.8466226752726331, 0.865810524133724, 0.8819730097475471, 0.8966162974520947, 0.9088963157449207, 0.9148631973800987, 0.909411611198444, 0.8898869939568396, 0.856539062367617, 0.8111673355046237, 0.7562603787362674, 0.6944995059121073, 0.6284615834344798, 0.5604576348306853, 0.49246697025214436, 0.426133161466161, 0.36279525218598385, 0.3035350223219893, 0.2492268932216518, 0.20058034906295796, 0.15816605277176843, 0.12241781597242975, 0.0936063051338567, 0.07179133134573204, 0.05677859057738427, 0.0481173595290961, 0.045153398697984265, 0.047112974693633874, 0.05318295022246433, 0.0625682151375945, 0.07452503813299208, 0.08837705128742851, 0.10352175812663794, 0.11943304629838111, 0.13566191868624627, 0.15364953197982112, 0.18675308189861894, 0.22964605528892443, 0.28201204070343583, 0.34258735222731274, 0.4089556051819207, 0.47750942015744613, 0.5437994268695385, 0.6034496726973358, 0.6536078358103232, 0.6944317524797569, 0.7291171633477813, 0.7611861897923142, 0.7917154859958638, 0.8197313186186693, 0.8438162113672278, 0.8635957001815583, 0.8802452261147058, 0.894991652963371, 0.9070298571108524, 0.9126768940061059, 0.9069779321401303, 0.8871476019211382, 0.853342033525025, 0.8074134102072444, 0.751952636963754, 0.6897308835042752, 0.6233831808322255, 0.5552481786585989, 0.48730962853548554, 0.42119975809139787, 0.35823592019047323, 0.2994711868459849, 0.2457460453842387, 0.19773181769410667, 0.15595774010319075, 0.12081478018132293, 0.0925332990312987, 0.07114215051740902, 0.05643286927827004, 0.04795983811263932, 0.04508816255067402, 0.04706959249159526, 0.05311636728815641, 0.06245523811158041, 0.07435926714154575, 0.08816335484225729, 0.10327115404377155, 0.119158674092959, 0.13537639826578585, 0.16016237623242568, 0.19354512894789014, 0.23649880480999855, 0.28860580064843255, 0.3485086024206932, 0.41374569454038657, 0.4807620842008226, 0.5452894426967718, 0.6032469586689012, 0.6521047459044877, 0.6921766045296175, 0.7264939842952797, 0.7583231384445666, 0.7887102655528712, 0.8167687210146499, 0.8411684297790986, 0.8614797628746775, 0.8785657048458327, 0.8933330514696587, 0.9049851103049531, 0.9101366597451551, 0.9040270012880777, 0.8837705592331775, 0.849432405633965, 0.8029115788690039, 0.746896161947465, 0.6842415811256798, 0.6176346326663834, 0.549435026382573, 0.481624958359966, 0.4158202898649487, 0.3533126884228611, 0.29512339294359413, 0.24205649700818752, 0.194743249421458, 0.15367014045067284, 0.11918474463531065, 0.09147745217797632, 0.07054703104107124, 0.05617143084920914, 0.04791002579952139, 0.04514703444337123, 0.047160003002140016, 0.05318748913844881, 0.062479390431035814, 0.07432685756887894, 0.08807712677043952, 0.10314075654631102, 0.11899637898841395, 0.135194309925768, 0.16685041989470145, 0.20047740022342414, 0.24344870933326357, 0.295251164898525, 0.35444419498795765, 0.4185364825534901, 0.48404097068458185, 0.5468802075952753, 0.603265603010242, 0.6509632762221171, 0.6903973694944717, 0.7244025649007964, 0.755981996380241, 0.7861606072030464, 0.8141737970367825, 0.8388103035966227, 0.8595957146637562, 0.8770750832244096, 0.8917967929209734, 0.9029311928679262, 0.9074038823869618, 0.9006795320160703, 0.8798241242617751, 0.8448379710385879, 0.7976652356582754, 0.7410822236848537, 0.6780183407827564, 0.6112021764889504, 0.5430056338118061, 0.4754020248862841, 0.40998513386040647, 0.3480166564543844, 0.2904828150302837, 0.2381489309889036, 0.19160444507913046, 0.15129202703778305, 0.11751557705922266, 0.09042605292773992, 0.069993095328485, 0.05598168547530252, 0.047956117470827925, 0.04531944983144154, 0.04737517901228175, 0.05338892637607073, 0.06263486526922482, 0.07442343486790348, 0.08811522292179991, 0.10312842443680034, 0.11894479320808507, 0.13511485079918034, 0.17370171415149332, 0.20754031021633815, 0.25049144560453696, 0.3019531711225891, 0.36041346702373694, 0.4233663808509843, 0.4874067406662792, 0.5486542064326343, 0.6036033115952347, 0.6502843410455454, 0.6891883523964578, 0.7229320497481161, 0.754257845916495, 0.7841745271131566, 0.8120653555162209, 0.8368658438853931, 0.8580721593865439, 0.8759136022547881, 0.8905435981555764, 0.9010436498998473, 0.9046422510950344, 0.8970572312672205, 0.8753787835193814, 0.8395890980567846, 0.7916803536169947, 0.7345046781182825, 0.671050528623726, 0.6040746870069026, 0.5359500434578446, 0.4686323619487693, 0.40368696896980477, 0.3423410382566377, 0.285542562159824, 0.23401581458509563, 0.18830687940937163, 0.1488137697668012, 0.11579667257562909, 0.08936782498029225, 0.0694687722223509, 0.05585218354147034, 0.048087248410434685, 0.04559557195257291, 0.04770662587649552, 0.05371366273933978, 0.06291610783370807, 0.07464478787469128, 0.08827459743747765, 0.10323206459374595, 0.11900255651800429, 0.1351371933962403, 0.1807061287780381, 0.2147267178345655, 0.2576256132288262, 0.3087198638325867, 0.36643812173819934, 0.4282744185118171, 0.4909174354224085, 0.550686464552579, 0.6043449201391413, 0.6501525618585623, 0.6886282229819145, 0.7221586814112836, 0.7532336963694978, 0.782848281832052, 0.8105504132328033, 0.8354467694461173, 0.8570251254259127, 0.8752091984881093, 0.8897230035346191, 0.8994870397734138, 0.9020006785824372, 0.8932682287017117, 0.8704973440902423, 0.8337131022806413, 0.7849626112892863, 0.7271586475506009, 0.6633296285668433, 0.5962435702501283, 0.5282609628074639, 0.46131012657838444, 0.3969209561401237, 0.3362813465064175, 0.28029785795094125, 0.22965157081616247, 0.18484385938030806, 0.14622747479513437, 0.11401907126023844, 0.08829302607600173, 0.06896388462580114, 0.05577270063624251, 0.04829358338255324, 0.0459663857050471, 0.048146475154197316, 0.05415514213687364, 0.06331789107663485, 0.07498693085921923, 0.08855235068198364, 0.10344966649704884, 0.11916833913114136, 0.13526049950036612, 0.18785514612734922, 0.22203156399793986, 0.26485212216468146, 0.31556134845545303, 0.372540905874867, 0.43329856395576993, 0.4946266077342324, 0.5530429373374945, 0.605561705129619, 0.6506367772624345, 0.6887809807381687, 0.7221462080502083, 0.7529804331813565, 0.7822650818932456, 0.8097215151545775, 0.8346481524811448, 0.8565508231883485, 0.8750660339734789, 0.8894570355462357, 0.8983967269584805, 0.8995961754650476, 0.889393775887585, 0.8652258991998698, 0.8272289661664555, 0.7775146441034717, 0.7190392448357948, 0.6548487500058844, 0.5877026590226698, 0.519933836912649, 0.4534322433238034, 0.38968490505650066, 0.3298355604026879, 0.27474620100662894, 0.22505272709667265, 0.18121065669491188, 0.1435270964766935, 0.11217554805973531, 0.08719351997563965, 0.06846971103429667, 0.05573429649171105, 0.048566379609799176, 0.046423766747315576, 0.048687556692503936, 0.05470733834332411, 0.06383537807318312, 0.07544615540416846, 0.08894576924218087, 0.10377933035743062, 0.11944085943670013, 0.13548393003454584, 0.1951415816831799, 0.2294514344160956, 0.27217352125318284, 0.3224888360979214, 0.37874436903924646, 0.4384742680730514, 0.4985818614819405, 0.5557794726323192, 0.6073112306944944, 0.6517907411115906, 0.6896966719046053, 0.7229459910003134, 0.7535565514797549, 0.7824941598172319, 0.8096548826648337, 0.8345451862826148, 0.8567198286138029, 0.8755545695755085, 0.8898246272449772, 0.897859979088661, 0.897497409259709, 0.885477155441491, 0.8595864903998505, 0.8201429493484116, 0.7693337180052046, 0.7101404921526612, 0.6456022223832171, 0.5784481431174763, 0.5109669296182623, 0.4449985436283702, 0.38197942842847415, 0.3230042764912756, 0.26888750492823354, 0.22021804056297134, 0.17740461474715452, 0.14070852280168775, 0.11026067674791618, 0.0860628235979469, 0.06797902296209793, 0.05572934993569814, 0.048898025599411116, 0.04696052714878432, 0.04932344957871293, 0.05536480703701077, 0.06446417032922172, 0.0760190711947181, 0.0894523570418777, 0.10421928796945246, 0.11981889585675923, 0.1358066504346326, 0.20255923962178957, 0.2369840627136773, 0.27959329136375044, 0.3295137117026544, 0.3850697390750426, 0.4438332479398881, 0.5028237716963491, 0.5589412295700117, 0.6096375358884293, 0.6536538451095226, 0.6914118940559894, 0.7245969180225219, 0.7550077555895903, 0.7835901049051235, 0.8104093098167899, 0.8351911868951587, 0.8575731318325103, 0.876704283067017, 0.8908491190403732, 0.8978967322191218, 0.8957112075052188, 0.8815159107759851, 0.8535720941601951, 0.8124455097948599, 0.760410071000359, 0.7004545645585899, 0.6355853411476349, 0.5684785643094118, 0.5013614262266817, 0.43601190485710434, 0.37380808480009686, 0.3157908419973702, 0.26272421716406386, 0.21514859971767936, 0.1734252303685796, 0.1377696353956237, 0.10827086941623301, 0.08489613100782689, 0.06748610009889439, 0.055751571792361565, 0.04928205767832228, 0.047570438969156914, 0.05004851255385531, 0.056122720066575094, 0.06520034146937159, 0.07670263494473106, 0.09006985671152276, 0.10476791547453712, 0.12030129221265355, 0.13622783116043044, 0.21010251134496333, 0.24462778708561891, 0.2871151234929572, 0.3366466529361695, 0.39153593680738963, 0.4494025140413572, 0.5073851426776275, 0.5625624475195311, 0.6125715249626781, 0.6562517950821721, 0.693950140801125, 0.7271252026854798, 0.7573664976852638, 0.7855924049940713, 0.8120257179666546, 0.8366168771601172, 0.859120364872119, 0.8784999087792189, 0.8924917268899635, 0.8984474445119376, 0.8941759819885401, 0.8774583834391824, 0.8471443383521795, 0.8041098085295315, 0.7507260961384244, 0.6899714560893058, 0.6247943152414928, 0.5577948996978447, 0.4911215674648534, 0.42647839224239237, 0.3651775102558841, 0.30820147000745785, 0.2562614159608058, 0.20984790209321225, 0.16927421071816567, 0.13471034503396573, 0.10620439283145608, 0.08369031579916095, 0.06698672491099686, 0.05579599756746337, 0.049713156037636624, 0.048248237174799924, 0.05085789459057258, 0.056976881975057236, 0.06604045589818289, 0.07749416679835747, 0.09079626042871392, 0.10542373729163704, 0.12088695608689662, 0.13674664309572998, 0.2177659242436315, 0.25238097125107134, 0.29474220032345755, 0.34389682344856837, 0.39815874484463465, 0.4552036326998717, 0.5122905567351758, 0.5666664767334777, 0.6161314721526928, 0.6595972230721519, 0.6973220405443673, 0.7305441322209992, 0.7606515072515002, 0.7885251443151866, 0.8145272569343347, 0.838830911231722, 0.8613403342270601, 0.880881595246865, 0.8946524826842703, 0.8993795160524914, 0.8927645199627807, 0.87320498447933, 0.8402340902577425, 0.7950919128084913, 0.7402564564428438, 0.6786791260192127, 0.6132264474447225, 0.5464007482095316, 0.4802548205395239, 0.4164074051415695, 0.35609753858009874, 0.3002453355442365, 0.24950688462173568, 0.20432190763457447, 0.16495550562355626, 0.13153260351073373, 0.10406136284968392, 0.08244391329794404, 0.06647815831383971, 0.05585896169341123, 0.05018712206328904, 0.048989603342960125, 0.0517475264262002, 0.05792372890065342, 0.06698157212339681, 0.07839135362984304, 0.09162980950528166, 0.10618542055445754, 0.12157484980228346, 0.13736224773939631, 0.22554364792560752, 0.26024139785240424, 0.30247650150698036, 0.35127116228012156, 0.4049501385498438, 0.46125220853770066, 0.5175561672365326, 0.5712660020161721, 0.6203235896022361, 0.6636902451337204, 0.7015255402046435, 0.734853813876486, 0.764867344626433, 0.7923968049416152, 0.8179198078512818, 0.8418214874910799, 0.8641837633300071, 0.8837487853216779, 0.8971773726557757, 0.9005013732630127, 0.8912939804120978, 0.8686138390461816, 0.8327447780188844, 0.7853326582179578, 0.7289691372844112, 0.6665641394105639, 0.6008805575929922, 0.5343026248375289, 0.46877208820577415, 0.40581182673117294, 0.3465813084171201, 0.29193465117324235, 0.24247116213892717, 0.19857906744372417, 0.1604753156017183, 0.12824039257917585, 0.10184371795599553, 0.08115708392256846, 0.06595909798650665, 0.05593805508459007, 0.05070083874778894, 0.04979113168124483, 0.05271409393665197, 0.05896031003129232, 0.06802123048503184, 0.07939223871813555, 0.09256898204132707, 0.10705175949759771, 0.12236397382132667, 0.1380737822756145, 0.2334289697767492, 0.26820564011782366, 0.3103181614704269, 0.35877379045631685, 0.4119177822287321, 0.46755756817980043, 0.5231896942410842, 0.5763634090192775, 0.6251426329535885, 0.6685189878801167, 0.7065460807139257, 0.7400409624112696, 0.7700040016236738, 0.7972001167863758, 0.8221927070478169, 0.8455587775868226, 0.8675779328266983, 0.8869671608904822, 0.8998690100203482, 0.9015765404080709, 0.8895392535050353, 0.8635098461554601, 0.8245580617203451, 0.774760992618965, 0.7168273625009263, 0.6536127734366404, 0.5877576369016666, 0.5215103564125966, 0.456687951552604, 0.39470817379303913, 0.3366453548628364, 0.28328472031124613, 0.235167569082436, 0.19263032743165281, 0.15584207568726607, 0.12483969057072222, 0.09955517290490665, 0.07983155897861366, 0.06542962087113544, 0.056032067761497495, 0.05125221603891722, 0.05065027901932756, 0.05375499437394449, 0.060084251837371344, 0.06915742505234873, 0.0804951972977449, 0.0936124679993085, 0.10802164938087083, 0.12325334261326382, 0.13888033983536427, 0.2414137773998006, 0.2762684230930126, 0.3182649249116206, 0.366405554343489, 0.41906468930939333, 0.47412262493053803, 0.5291905870132472, 0.581951258004723, 0.6305725359462852, 0.6740601118605626, 0.7123568070456213, 0.746078768025544, 0.7760365710661208, 0.802911906306756, 0.827319483949349, 0.8499977805537159, 0.871432715616477, 0.890377804205436, 0.9024988110741624, 0.9023375185351056, 0.8872475067794755, 0.8576960117536271, 0.8155412992810351, 0.7632985153528684, 0.7037922334182467, 0.6398125227718972, 0.5738617012477208, 0.5080375623023093, 0.44402093706701606, 0.3831167407805275, 0.3263096817862738, 0.27431396592002344, 0.22761220742331761, 0.1864891063073237, 0.1510664150911149, 0.1213384172030575, 0.09720115337228982, 0.07847057013444364, 0.06489111139721249, 0.05614091833615614, 0.051840123081846934, 0.05156530062586481, 0.05486827671144162, 0.06129370537731496, 0.070388559437186, 0.08169889748440717, 0.09475913108188919, 0.1090940497680098, 0.12424195336168752, 0.13978094552247783, 0.2494881578975708, 0.28442207866219454, 0.32631175867799267, 0.3741637206028726, 0.42638904117061793, 0.4809439039201362, 0.5355503238216581, 0.5880128416181803, 0.6365870753293534, 0.6802793602946996, 0.7189188515544866, 0.752926883479758, 0.7829250142209042, 0.8094929133704658, 0.8332584042637181, 0.8550811078785859, 0.8756473352207773, 0.893807761228389, 0.90481974380917, 0.9024998199574152, 0.8841532595493767, 0.8509660298279579, 0.8055561661070099, 0.7508648502135475, 0.6898258991568199, 0.6251539063904582, 0.5592007938792484, 0.49390219424484155, 0.43079379389189054, 0.37106173009160776, 0.31559781013436067, 0.2650439318133372, 0.21982393276511644, 0.18017124721181044, 0.14616109261279353, 0.11774635701807493, 0.09478871249801987, 0.07707876382150988, 0.06434617698829223, 0.05626557220291434, 0.05246430944132904, 0.052535173971532234, 0.056052567694460764, 0.06258727712112161, 0.07171338623315435, 0.08300224604511058, 0.0960079568494871, 0.11026793734089038, 0.1253287483109071, 0.14077452906920068, 0.2576402609724089, 0.2926563811005486, 0.33445066451729943, 0.38204182810716525, 0.43388415502585076, 0.48801170756800294, 0.5422528248613516, 0.5945228115476986, 0.6431505724283058, 0.6871321594558951, 0.726181725227699, 0.7605315699307941, 0.7906140684269002, 0.8168875822516966, 0.8399526494698635, 0.8607411407680254, 0.8801170045046952, 0.897081280482075, 0.9065794240593457, 0.9017765876884023, 0.8799938444303445, 0.8431172666081981, 0.7944677692658008, 0.7373834518254863, 0.6748950345351704, 0.6096324562534253, 0.5437880748294579, 0.47912710223225785, 0.41703376340700493, 0.35857135860251876, 0.30453679659962263, 0.2554992534232873, 0.21182429728412686, 0.1736949421947547, 0.1411409076485305, 0.11407506185519811, 0.09232643020561332, 0.07566210182908295, 0.06379855244109778, 0.056407950336554324, 0.0531253175341303, 0.05355951289029223, 0.05730698572868609, 0.06396394407072364, 0.07313092973584975, 0.08440431842843621, 0.09735798664417528, 0.1115422490182959, 0.12651257208034583, 0.1418598952916786, 0.26585641805023646, 0.30095873870078316, 0.3426706883766047, 0.3900296894252421, 0.4415385870889204, 0.49531040178609476, 0.5492749585361412, 0.6014478643658607, 0.6502186393036106, 0.6945642930479715, 0.7340838465608709, 0.7688260412544926, 0.7990333530334673, 0.825023884882914, 0.8473300592018147, 0.8669010167975065, 0.8847384013591377, 0.9000309464738298, 0.9075337199282854, 0.8998943256908092, 0.8745250549655622, 0.833963401424577, 0.7821536222964951, 0.7227874397957358, 0.6589743889579509, 0.5932507564806843, 0.527642926055001, 0.4637405884535454, 0.4027728206246925, 0.34567792918441365, 0.2931572164068802, 0.24570759460425307, 0.20363746155237847, 0.16708062864236578, 0.1360225865868277, 0.11033773277665887, 0.08982429623609031, 0.07422774941702509, 0.06325299480915123, 0.05657083065110666, 0.05382438863457639, 0.054638474955786026, 0.05863104548732026, 0.0654229546556914, 0.07464039155611121, 0.08590427239455073, 0.09880823723596524, 0.11291581706512027, 0.12779212589621497, 0.1430356938070393, 0.2741213723654865, 0.30931446376585364, 0.35095807603440093, 0.3981135225741901, 0.44933635369534575, 0.5028188040073535, 0.5565871246438646, 0.6087474799397482, 0.6577389766841509, 0.7025126677778505, 0.7425532316899611, 0.7777310444158909, 0.8080977451343193, 0.833813294591318, 0.8553025186769218, 0.8734740728212944, 0.8894127201456181, 0.902507522937175, 0.9074613405046746, 0.8966102737291818, 0.8675363686388632, 0.8233459818436137, 0.7685119001062941, 0.7070250789758763, 0.642050174783198, 0.5760203996870591, 0.510791998286772, 0.4477769090709967, 0.3880478655960189, 0.3324178552483458, 0.2814931036579636, 0.23569954692658152, 0.1952900733541904, 0.16035085671109972, 0.1308246443782873, 0.1065490819327563, 0.08729357793512907, 0.07278395235179713, 0.06271517046824779, 0.05675774390402119, 0.0545633649084184, 0.0557726652324847, 0.06002455705835749, 0.06696371824148428, 0.07624103880014702, 0.08750124448645527, 0.10035760701609547, 0.11438729921104043, 0.12916592133835186, 0.1443003897103252, 0.28241852537365003, 0.31770703946825074, 0.35929651588117173, 0.40627618665304294, 0.4572572507282186, 0.5105106548725391, 0.5641539003248012, 0.616374707106918, 0.6656522285572485, 0.7109061813154516, 0.7515083617920559, 0.787155707083092, 0.8177081016668052, 0.8431510822867047, 0.8637652700965448, 0.8803617915547205, 0.8940449121188432, 0.9043864184519426, 0.9061802180407336, 0.891731338216072, 0.8588644866889842, 0.8111441331108498, 0.7534684725539327, 0.6900645724783492, 0.6241230844811951, 0.5579637344378536, 0.4932701276477074, 0.43127668410489717, 0.37290084316989636, 0.3188316264125198, 0.26958184269854774, 0.22550848794744455, 0.18681111161751415, 0.15353012680959338, 0.1255672211262407, 0.10272517500438366, 0.08474667399163341, 0.07133990437856133, 0.0621915360837752, 0.056972866128555316, 0.05534458994976538, 0.05696303979866435, 0.061487524455392434, 0.0685856884521259, 0.0779320750535859, 0.08919422847097033, 0.10200477178594919, 0.11595510851163957, 0.13063223676120972, 0.14565223704301128, 0.29073017339638446, 0.3261183799187029, 0.36766742671684255, 0.41449749383496887, 0.46527725091937466, 0.5183551562919153, 0.5719347361533668, 0.6242769913707757, 0.6738928950433223, 0.7196666972342748, 0.76085923456287, 0.7969986720992452, 0.8277523957632376, 0.8529171352326278, 0.8725966124533424, 0.8874510096106255, 0.898538116383404, 0.9055677200059454, 0.9035650239624862, 0.8851315087434334, 0.8484033635452306, 0.7972817248010314, 0.736982325062757, 0.671897901525436, 0.605210759238685, 0.5391152928682502, 0.475121056771166, 0.41428717881784394, 0.3573787710414339, 0.30496370419004365, 0.2574640043512466, 0.21517039514807995, 0.1782316936683258, 0.14664469621276865, 0.12027189369652914, 0.0988832551077656, 0.0821969555479021, 0.0699056067737023, 0.06168921523403603, 0.05722090953240866, 0.05617081021484652, 0.05821081247408752, 0.06302004909574294, 0.07028824893763028, 0.0797124972396252, 0.09098193482576167, 0.10374807798797098, 0.11761734944598734, 0.13218907985356776, 0.14708925686748187, 0.2990377311466537, 0.33452908468757264, 0.3760502671700988, 0.4227545733207535, 0.4733689592750909, 0.5263175596465209, 0.5798846906860663, 0.6323970386020431, 0.6823903014424147, 0.7287101246604226, 0.7705085961072017, 0.807149521653035, 0.8381073093304463, 0.8629774815834591, 0.8816585479841511, 0.8946119203438391, 0.9027848302848759, 0.9059684777003796, 0.8995547959054769, 0.8767595491248914, 0.836109012838215, 0.7817315148749181, 0.7190491159891472, 0.6525435267131424, 0.5853495737575787, 0.5195228086272005, 0.456397905689663, 0.3968624254360892, 0.3415336589902257, 0.2908623381534445, 0.24518312158726158, 0.20472361258961824, 0.1695848441771377, 0.1397223540028614, 0.11496146262795834, 0.09504154941570081, 0.07965859638896722, 0.0684917217718258, 0.061215872464219695, 0.057507013706937365, 0.05704507954738772, 0.05951736793446846, 0.06462224399865893, 0.07207061368540846, 0.0815809526702641, 0.09286263289712024, 0.10558544907375547, 0.11937176779252612, 0.13383415967270015, 0.1486092215608729, 0.30732194314941885, 0.34291868845215123, 0.38442285466583026, 0.43102226768950835, 0.4815021086107042, 0.5343597890936765, 0.5879551923213654, 0.6406737075063301, 0.691069617488724, 0.7379475935977577, 0.7803533385420547, 0.8174904734100397, 0.8486402812129639, 0.8731866286630647, 0.8907988627617829, 0.9016986321549375, 0.9066623875496506, 0.9055145599641184, 0.8941406753564817, 0.8666320305357651, 0.8219985366042946, 0.7645161556111036, 0.6997027829797704, 0.6320478514976291, 0.5645956487947499, 0.49924776044511476, 0.4371633512202072, 0.3790631614076676, 0.325422306398431, 0.27657929532351766, 0.23278540026456074, 0.1942085678457361, 0.16090522439323818, 0.13279216374066544, 0.10965971509639436, 0.09121906026272975, 0.07714639426806957, 0.06710942182182292, 0.06077958654782062, 0.05783663884913304, 0.057970668674580256, 0.06088418382196484, 0.06629416360313811, 0.07393175480660105, 0.08353563591521809, 0.09483401644867165, 0.1075143271273934, 0.12121572117155903, 0.13556487081364232, 0.1502096465536804, 0.3155630844405495, 0.35126590578768535, 0.39276168721756055, 0.4392735467678617, 0.48964407946307376, 0.5424410862405802, 0.5960948176434213, 0.6490429222190779, 0.6998529171966474, 0.7472867106520947, 0.7902860380009352, 0.8278983092102837, 0.8592119569657121, 0.8833906902257382, 0.8998548759464294, 0.9085532155377662, 0.9100389884877914, 0.9041411390319931, 0.8873489955496209, 0.854818637745915, 0.8061444510270293, 0.7457063561586061, 0.6790152717788926, 0.6104854323557883, 0.543025050494117, 0.4783654037668601, 0.41748948892793325, 0.3609565691722828, 0.3091059703493567, 0.2621694985354556, 0.22031936192411364, 0.1836674373908193, 0.15222882054043563, 0.12588417363789312, 0.10439116542429502, 0.08743534317350793, 0.07467558582390213, 0.06577023678514632, 0.06038872471194898, 0.058215462513996646, 0.05895098114178551, 0.062312763608711075, 0.06803575218343275, 0.07587036616954385, 0.0855742710974664, 0.09689320439393906, 0.10953166643401685, 0.12314617427900608, 0.13737829119096745, 0.15188779019839493, 0.3237411515702922, 0.3595488706079215, 0.40104226361052986, 0.44747992787971375, 0.4977604310475837, 0.5505186637792138, 0.6042500756396646, 0.6574385950412283, 0.7086602664783116, 0.7566328745474074, 0.8001965986403621, 0.8382464777681475, 0.8696789337681344, 0.8934311104412113, 0.9086586904815938, 0.9150127572812179, 0.9127845885813324, 0.9017970261585836, 0.8792301260729491, 0.8414280712817479, 0.7886663624380023, 0.7254168132530112, 0.6570945939594715, 0.5879579931110371, 0.5207331802407573, 0.4569642801734839, 0.39745736797835196, 0.34261581205122865, 0.2926499025878116, 0.24769057325529972, 0.2078354173219271, 0.17314375932089804, 0.1435925905641856, 0.11902909465449518, 0.09918077573184017, 0.08371027508117501, 0.07226165796798015, 0.06448590133025114, 0.06005181953664385, 0.05864928119941207, 0.05998947668889271, 0.06380458096356842, 0.06984681126525386, 0.0778848622290233, 0.08769417112295091, 0.09903684964581863, 0.1116339764467392, 0.1251597184758223, 0.13927119343757072, 0.1536406618321871, 0.33183604450649257, 0.3677453693888649, 0.4092393985176353, 0.4556118940476599, 0.5058154321525242, 0.5585483569731543, 0.6123661873944247, 0.6657935481949186, 0.717410823145788, 0.7658906267402875, 0.8099739616423287, 0.8484072996126187, 0.879896656879008, 0.9031486427672031, 0.917043227208586, 0.9209180131534851, 0.9147798364452536, 0.8984472830880084, 0.8698522722631239, 0.826597231424804, 0.7697219445444718, 0.7038006523301368, 0.6340815039729062, 0.5645923572936071, 0.49783339793571324, 0.43514522017901014, 0.3771562053357931, 0.32411937077715314, 0.2761227600701452, 0.23320230678628498, 0.19538537150219393, 0.1626819930183127, 0.13503406876557644, 0.11225794814101014, 0.09405366089306416, 0.08006381694739542, 0.06992015902605489, 0.06326820487933854, 0.05977745016198199, 0.05914391783331191, 0.06108960260252691, 0.06536103538458249, 0.07172698397758454, 0.07997340318525512, 0.08989232520941376, 0.10126125298845626, 0.11381739507798591, 0.12725261129148924, 0.1412400684962306, 0.15546503748649204, 0.33982773965966867, 0.3758330670573906, 0.41732752955325975, 0.4636393035999107, 0.5137725827854366, 0.5664852631112699, 0.6203878511347332, 0.6740404226697617, 0.7260239321043134, 0.7749650098032358, 0.8195078346696221, 0.8582541975516942, 0.8897223142220586, 0.9123871858393042, 0.9248477319461341, 0.9261212291637121, 0.9159213826452818, 0.8940738260424578, 0.8592979827507464, 0.8104834620718382, 0.749498447612203, 0.6810430647426993, 0.6101451135886335, 0.5405374494196802, 0.4744549536961495, 0.4130198782623882, 0.356682300991281, 0.305550194801703, 0.25959590037531033, 0.21876602904295814, 0.1830218641713758, 0.15232702609479778, 0.12659092826759186, 0.10560168686960258, 0.08903478403192333, 0.07651577596903716, 0.06766651325063058, 0.06212884650497219, 0.05957412932835887, 0.05970513599859392, 0.062254733156299785, 0.06698341805721136, 0.07367575261383633, 0.08213393462555013, 0.09216548369226651, 0.1035624606146372, 0.11607777194981758, 0.1294208291106757, 0.1432811589092065, 0.15735748218317863, 0.34769645396050275, 0.38378972427449326, 0.4252810135491323, 0.4715317859450327, 0.5215951189797444, 0.5742843601778508, 0.6282599828828038, 0.6821125618137168, 0.7344201975518733, 0.7837629051191258, 0.8286903968385925, 0.8676638794474595, 0.8990175960972541, 0.9209971666899723, 0.9319215937698496, 0.9304896440809948, 0.9161238798368522, 0.8886746716375843, 0.8476618248057592, 0.793259001089041, 0.7282052342900028, 0.657354650631864, 0.5854777408785828, 0.5159605348891477, 0.4507403276756147, 0.3907088589198071, 0.33613768951402023, 0.2869946913015987, 0.24314257943887418, 0.20444392997680283, 0.17079775387099116, 0.1421236296254057, 0.11830050196360872, 0.09909079732364576, 0.08414865124683757, 0.07308557340447314, 0.06551584251514678, 0.06107929713222898, 0.05945019763173054, 0.06033856150738945, 0.06348811691366879, 0.06867288638648564, 0.07569244510506248, 0.0843642316650528, 0.09451023133219785, 0.1059363462605439, 0.11841074891967945, 0.13166012618675965, 0.1453904987708531, 0.15931437740412832, 0.3554227997081463, 0.39159340477414006, 0.4330744095617358, 0.47925911921779973, 0.5292464944723045, 0.5819010970379777, 0.6359284234810335, 0.6899448573247509, 0.7425225138205694, 0.7921943217154617, 0.837417936592942, 0.8765184100711166, 0.9076512284816046, 0.9288383541899847, 0.938126550464357, 0.933905996799869, 0.9153196090708644, 0.8822622910954312, 0.8350484030284875, 0.7751068145539601, 0.7060673463438139, 0.6329647638615319, 0.5602892392625125, 0.4910428733117249, 0.42684209564437525, 0.3683395086995034, 0.31562857467564537, 0.2685415822670991, 0.22683707438105388, 0.19029833481575698, 0.15876546280132894, 0.13211586336975006, 0.11019926486291307, 0.09275489774475931, 0.07941901666218187, 0.06979202456763131, 0.06348279898845641, 0.06013067125944238, 0.05941372619678628, 0.061049611731863435, 0.06479283143422321, 0.0704304454515414, 0.0777762464533514, 0.08666194124342819, 0.09692304835440549, 0.10837867974177556, 0.12081183233238642, 0.1339660944371182, 0.1475639572893918, 0.16133195215275842, 0.36298792976607774, 0.39922267141746337, 0.44068274634282156, 0.48679158621651397, 0.53669083403535, 0.5892919484179084, 0.6433406034126573, 0.6974745457189412, 0.7502570370691555, 0.8001736095625472, 0.8455923841017702, 0.8847071218617402, 0.9155012338012491, 0.9357821652837145, 0.9433381298918887, 0.9362684776390195, 0.913456869652953, 0.8748614442075379, 0.8215703458044445, 0.7562171600236105, 0.6833198553220462, 0.6081149648415005, 0.5348009913101398, 0.4659749579604132, 0.40291945045723054, 0.34604346146124854, 0.2952636027983645, 0.2502806658059698, 0.21075375807364868, 0.17639096334899784, 0.1469763129241735, 0.12234643490218479, 0.10232229107006924, 0.08662235526346221, 0.07486861046824522, 0.06665313749697876, 0.06158141231967318, 0.05929361015810364, 0.05947242875836023, 0.06184343291770775, 0.06617174479360985, 0.07225693469319719, 0.07992621203039615, 0.0890246193932192, 0.09940036028832819, 0.1108851835663626, 0.12327645538463002, 0.1363342202462693, 0.14979728326758077, 0.16340631602983885, 0.37037367260125137, 0.4066567696761573, 0.4480817722399436, 0.49410030563887586, 0.5438933541525915, 0.5964149288956712, 0.6504461576476657, 0.7046419441593674, 0.7575540812735088, 0.8076205730962215, 0.8531227050697492, 0.892128327014286, 0.922456906417405, 0.9417136043247176, 0.9474469246207099, 0.9374906655111348, 0.910498073616324, 0.8665068433173314, 0.8073461199577513, 0.7367843827780637, 0.6602026509742703, 0.5830525473864006, 0.5092397021583066, 0.4409515114503938, 0.3791345179254306, 0.3239540324538144, 0.2751520365578522, 0.23230152155757952, 0.19496615406961337, 0.16278220171057062, 0.13547990000840324, 0.11285604534938556, 0.09470273808189064, 0.0807199525603893, 0.07051890231541252, 0.06368593604786146, 0.05982495432030557, 0.058578178153988, 0.05963358389956325, 0.0627248455499905, 0.0676274832840442, 0.07415301838052363, 0.08214128062992682, 0.0914497623344202, 0.10193857798801209, 0.1134515791472901, 0.12580003070421064, 0.13875993608886592, 0.15208614837580203, 0.16553349288355912, 0.3775626566322481, 0.4138757973568399, 0.4552481857478953, 0.5011575361370628, 0.5508207475230227, 0.6032300610279879, 0.6571974836924637, 0.7113911156849696, 0.7643489237514718, 0.8144614638369513, 0.8599261283820527, 0.8986908030646142, 0.9284205039341529, 0.9465329540382726, 0.950359931267531, 0.9375017361091772, 0.9064181727837138, 0.8572409910401801, 0.7924976470956303, 0.7170035574376687, 0.636955298513209, 0.5580240250851488, 0.4838311048920114, 0.41616640981952463, 0.3556486107729656, 0.3022035611827349, 0.2554018940717558, 0.2146922017578176, 0.1795460004059548, 0.14953041284417606, 0.12432355591622844, 0.10368289149193624, 0.0873714750714969, 0.07507263227873504, 0.06638990958666485, 0.06090631166503235, 0.0582258233404897, 0.05799377314454776, 0.059903967932501745, 0.06369829770648597, 0.06916240468204549, 0.07611917871879612, 0.08442028603341709, 0.0939348313635823, 0.10453412918357616, 0.11607362399115778, 0.12837799389605953, 0.1412386659506573, 0.15442618769874966, 0.167709453816402, 0.38453842336433197, 0.42086085951140106, 0.46215984520296266, 0.5079369511871988, 0.5574415285982641, 0.6096997936432339, 0.6635502370981178, 0.7176704553253099, 0.7705825076860666, 0.8206298345373018, 0.8659291853698131, 0.904315030341697, 0.9333086520810336, 0.9501572675755324, 0.9520020114111495, 0.936247189306027, 0.9012038362111838, 0.8471125338236817, 0.7771477478734891, 0.6970666428520678, 0.6138116040889646, 0.5332684458552858, 0.4587937064549564, 0.39180771588484553, 0.33261856626075786, 0.2809208033234527, 0.23611811816972478, 0.19753794905647543, 0.16456234876924003, 0.13669130509229616, 0.11355192546025508, 0.09486247211466306, 0.08035692555499235, 0.06970333143042334, 0.06250005497024952, 0.058328906051516055, 0.056795449574607304, 0.0575490520035806, 0.06028979863488615, 0.06476782621821228, 0.07077857652670666, 0.07815571078513828, 0.08676196651101045, 0.09647727204243034, 0.10718348280690979, 0.11874714110328805, 0.13100583900960108, 0.1437658642840806, 0.15681303658821438, 0.1699301485921868, 0.39128552883540285, 0.42759420763778877, 0.468795956397294, 0.5144138832228269, 0.5637263380384274, 0.6157893672350179, 0.6694637598651566, 0.7234331902648056, 0.7762020316673818, 0.8260672411419608, 0.8710685435733628, 0.908934163206829, 0.9370534483878027, 0.9525216380795208, 0.9523174228994101, 0.9336902587417674, 0.8948536983157186, 0.8361754732365775, 0.7614174742388391, 0.6771578402301153, 0.5909935458219946, 0.5090104701563768, 0.4343327614163175, 0.36805301550835057, 0.31019331062707955, 0.2602284679195599, 0.21740083781977732, 0.1809199798366417, 0.15008072212755452, 0.1243173695379698, 0.1032066458364877, 0.08642752698701883, 0.0736850427131581, 0.0646328959120506, 0.05886607181621922, 0.05596702471414017, 0.05554422151019195, 0.057251871003466875, 0.060796689787563085, 0.06593702535804138, 0.07247775892313668, 0.08026271876371627, 0.08916497213090435, 0.0990745284103702, 0.10988316721208571, 0.1214680417226447, 0.13367914690528043, 0.14633704868559888, 0.1592423633028207, 0.17219153474870696, 0.3977896329702625, 0.43405936245536514, 0.4751372371862075, 0.5205655359259016, 0.5696482046241056, 0.6214671243010863, 0.6749014384458208, 0.7286377890664405, 0.7811614190591145, 0.8307237828904929, 0.8752916228661182, 0.9124947196651048, 0.9396032371262111, 0.953580165706083, 0.9512712566064052, 0.9298139852861099, 0.8873799583470842, 0.8244895291850025, 0.7454234362814879, 0.6574478915540745, 0.5687042504841364, 0.4854533490112719, 0.4106347517638784, 0.34506525980506186, 0.2885107848657391, 0.24024098761893609, 0.19934377794691, 0.16491436779911947, 0.136162349891212, 0.11245738926446738, 0.09332609640786718, 0.07840797775860886, 0.06737931648083906, 0.059880051162079034, 0.05550295086820625, 0.05383257934997693, 0.054481432776237654, 0.0571092408911518, 0.06142961620754078, 0.06720902269361026, 0.07426139145570132, 0.08244011317781968, 0.09162787002811476, 0.10172405300150741, 0.11262978328982992, 0.12423234238212141, 0.13639360745125323, 0.14894782672631424, 0.1617098972522394, 0.17448960396045965, 0.40403757653418826, 0.44024121973166175, 0.48116605846231103, 0.5263711640051251, 0.5751827637967711, 0.6267047633819397, 0.6798309893571223, 0.733248276915628, 0.7854216629192198, 0.8345584750742038, 0.8785569869529658, 0.9149569775588448, 0.9409230219272493, 0.9533065113757684, 0.948850501453793, 0.9246235727745672, 0.8788115855532775, 0.8121216735337996, 0.7292753075796579, 0.6380873386529485, 0.5471197549848505, 0.46277233459759215, 0.38786273992934694, 0.3229893115082435, 0.26769534960235564, 0.2210625967591591, 0.18203286562766835, 0.14959105729451386, 0.1228634955773082, 0.10115601970123297, 0.08394519214208757, 0.07083085962997288, 0.061460776777380766, 0.055461404501410044, 0.05242391938568075, 0.05193605557565348, 0.053615247860706955, 0.05712729582622014, 0.06219288875229015, 0.06858646167045035, 0.07613058385478855, 0.084687608978157, 0.09414914793425305, 0.1044233134226856, 0.11542001336055874, 0.12703617718060484, 0.13914503640843398, 0.15159391748357073, 0.16421145289978595, 0.17682040539889773];\n",
       "const lower_is_better = false;\n",
       "const metric = \"accuracy\";\n",
       "const rel = false;\n",
       "const sd = [0.14716126797650353, 0.11831117714608393, 0.08856962699304777, 0.05946061197186729, 0.03469584233023398, 0.025548292031099748, 0.0361851599617857, 0.049175264899759694, 0.05853001715636772, 0.063970435550443, 0.0655195651718104, 0.06249089128814865, 0.05433311540833673, 0.041711110784601546, 0.027152562877911807, 0.016065842414691948, 0.014708660344268201, 0.01604606805251402, 0.013566668434039343, 0.006995095579741772, 0.0035702389325053705, 0.01856993128628975, 0.03858270315118923, 0.06252051149249457, 0.08819944793280327, 0.1134152575507305, 0.1363285297642641, 0.15552447578688272, 0.16997027963498335, 0.17894728719872774, 0.1819866243141343, 0.178821070056019, 0.1693606480123898, 0.1536987240599767, 0.13216085174366804, 0.10543576780193345, 0.07497388654216659, 0.04492707553954756, 0.03351802913194626, 0.057281091582617245, 0.09094253211814246, 0.12442749769576716, 0.15544433723161863, 0.18329394689251796, 0.20785766470020478, 0.2293015926119948, 0.24793067079570502, 0.26409814386845404, 0.2781486996856569, 0.2903871862313429, 0.14442458355414733, 0.11563026325873167, 0.08585303600380566, 0.056257539654832184, 0.02934125713685731, 0.015937263855605517, 0.028023947499077984, 0.04166715034912491, 0.05115968132164272, 0.05701775564216439, 0.05939519377860047, 0.05733011926406583, 0.0499752059686945, 0.03780830439646631, 0.02311381234151925, 0.01100192745836793, 0.010488217470174066, 0.013026347757547505, 0.011808920602594817, 0.0075183480427808555, 0.0025421378256408897, 0.015071786241248207, 0.03482512553020495, 0.059016639395604954, 0.08507276800044164, 0.11065645764297274, 0.13388529046593972, 0.15333353138310113, 0.1679696201451926, 0.1770802074219056, 0.1802011869474859, 0.17706576488156894, 0.16757545635909624, 0.15179843370445528, 0.13000105026609426, 0.10272968095259019, 0.07103126924719769, 0.03760355113643644, 0.021825338183080974, 0.05077051732473302, 0.08653834596655251, 0.12081628907395198, 0.15215755304028064, 0.18013895525230122, 0.20476213454617304, 0.22625639928115993, 0.244961498805299, 0.2612473682981307, 0.2754624036296943, 0.28790607358634096, 0.14195351169980838, 0.11343624090540992, 0.08399166740647465, 0.05456987449561614, 0.02672402923686173, 0.006806082535977584, 0.020775323029923982, 0.034607990279875114, 0.04391571315804035, 0.05011950936085322, 0.05341568422704995, 0.052453656048378434, 0.0460682560568141, 0.03459709027238938, 0.02013775312208499, 0.00693798724985349, 0.007031129373917772, 0.010332663087141083, 0.01025288239056458, 0.008355157829849386, 0.003567276571697581, 0.01190568322144139, 0.03156481252383064, 0.05603881639722089, 0.08242545939225823, 0.10830971696688604, 0.13178923244211604, 0.15143709676788222, 0.1662280076685603, 0.17545760997090548, 0.1786705690760172, 0.1756060003159897, 0.16616538320702193, 0.15040608824226873, 0.12856244321178875, 0.10109684825413291, 0.06879571696385552, 0.03308643095957946, 0.010900005062662208, 0.046342137075575836, 0.08335277623998123, 0.11793230548269068, 0.14929899300896227, 0.17721591369717166, 0.20176573610355253, 0.22322128990428783, 0.24194554489389258, 0.2583170691073158, 0.27268159714044793, 0.285327892549059, 0.13970441622949292, 0.11167618873972703, 0.0829257292936951, 0.05435934548862088, 0.02730519291603255, 0.003837564808922907, 0.015396079079631983, 0.028218876429511774, 0.0368302214293467, 0.043269937981888947, 0.04757543892748943, 0.04783921222314552, 0.042563767381002114, 0.03201134374142848, 0.01823077600566722, 0.004722337608767349, 0.004708232699960071, 0.007863939347314525, 0.008734459011159235, 0.009041248780074403, 0.00483869106914598, 0.00910802069855706, 0.0289087834473362, 0.05364933064339851, 0.08028962286564743, 0.10639043766993149, 0.1300461255171249, 0.1498348692691312, 0.1647409660071552, 0.17407199008817686, 0.1773850815651485, 0.17443071468235882, 0.16511903962297886, 0.14951180693281022, 0.12784112998324784, 0.10055468105700661, 0.06838656402872986, 0.03247297486587113, 0.006719000840153735, 0.044548476452036426, 0.08148529529032804, 0.11579727604979331, 0.14686724888637995, 0.17451441876935792, 0.1988544194667937, 0.2201812814654317, 0.23886853948525016, 0.2552947098666386, 0.2697960098998662, 0.28264477382915243, 0.13762391189032444, 0.1102780958000762, 0.08255036857063516, 0.055435023552589474, 0.03054720079234991, 0.01185377632776702, 0.013718295633245054, 0.02290343355743643, 0.029966598284879038, 0.03646537901329266, 0.04186817333893395, 0.04345209347744611, 0.03938614516310306, 0.02992515059067259, 0.017203937801005695, 0.005112427033716293, 0.004062566826752861, 0.005549803877101508, 0.007226158619224626, 0.009480224546686646, 0.005879800938914088, 0.006885346671343363, 0.026974176873617924, 0.051895440822689966, 0.07868379034282331, 0.10490409053206011, 0.12865444894291103, 0.14852084853354616, 0.16349912444980977, 0.17291112956395754, 0.17632991216756752, 0.17352257905247512, 0.16441643360487385, 0.14909237104469444, 0.12780925378347435, 0.10106757872341994, 0.06975607925781037, 0.035804852559853245, 0.015617053172559946, 0.04557506089965443, 0.08095758530078417, 0.11440574984384388, 0.14484839650500875, 0.1720172138727373, 0.1960099405511456, 0.2171186776330695, 0.23571446423538528, 0.2521667055724527, 0.266794848824896, 0.27984870720988836, 0.13565069319792133, 0.10915463284162287, 0.08272606386789537, 0.057500582280759154, 0.03537973504054948, 0.020048588739952362, 0.016429191833795626, 0.019354735592026974, 0.023461262348626864, 0.029705881327236307, 0.03628783033438154, 0.039245276866547905, 0.03643796145758389, 0.028169877830950766, 0.016703933934591176, 0.006571685068246191, 0.004700485010827892, 0.003425533033321099, 0.005911088782571643, 0.00974282382433446, 0.006693147237767942, 0.005688256356188309, 0.025842888916515892, 0.050795393939242504, 0.07760854815172583, 0.10384473166349187, 0.1276048745049434, 0.1474831832245067, 0.16248822233911797, 0.17195818804574758, 0.17548528804080585, 0.17285824935646882, 0.16402936820206904, 0.14911189786584414, 0.12841628066084268, 0.10254982228797636, 0.07269710064642522, 0.04195910385073113, 0.026418313255244647, 0.04907932986030321, 0.08170245341250247, 0.11372376823616515, 0.14321600177659022, 0.16970039032922363, 0.19321005449642353, 0.21401323172676193, 0.23246569808874132, 0.24891856459186928, 0.2636669391275004, 0.2769316771809293, 0.1337177259643252, 0.10820792744468076, 0.0832929785709662, 0.060225330322310255, 0.040917606360064564, 0.02785012051321364, 0.021589033159330022, 0.0183897822374886, 0.01763697026607429, 0.02299683260682327, 0.030829536193598683, 0.03516032774131855, 0.033609365147255654, 0.02656440195760799, 0.0163453381569105, 0.007732595979680566, 0.0055445391085162665, 0.0020254714231031333, 0.005248457936649997, 0.009947347474146315, 0.007302915544382092, 0.005838162120538425, 0.02551121152770424, 0.05032926989259285, 0.07704457591832257, 0.10319462735698022, 0.12688029852902452, 0.14670432548749832, 0.16168931645492676, 0.17119195832252895, 0.17482680685922597, 0.17240884053645328, 0.1639222077717149, 0.14952327661003062, 0.12959231013158026, 0.10487616098739297, 0.07690265323274019, 0.04968838061956019, 0.03721943754119049, 0.054395855948375336, 0.08357351589420013, 0.1136906640215718, 0.1419319350370296, 0.16753388151603224, 0.1904288402919558, 0.2108423784061073, 0.22910320603100914, 0.24553506205858033, 0.2604008907511207, 0.27388581889579117, 0.13175460922525814, 0.10733465351708309, 0.08408550676890264, 0.06330081901878581, 0.04661464264157897, 0.0351827105664327, 0.027573942648176395, 0.020169884869525444, 0.0133025597407523, 0.016350867341922513, 0.025490988820788665, 0.03112927333719479, 0.030790097579001096, 0.024947565971102075, 0.015828142394940153, 0.008175759093268165, 0.006093772942415671, 0.0027740672629553297, 0.005692900723120128, 0.010187189389712893, 0.007674806914681075, 0.006885137856455579, 0.025873721115328072, 0.050439513155507223, 0.07695387222057452, 0.10292511949755927, 0.12645643825601086, 0.14616148562458858, 0.16107917842692956, 0.17058726951977607, 0.17432591425350902, 0.17214058620477088, 0.16405293948999627, 0.15027018236713505, 0.13125278324853526, 0.10789663699155196, 0.08203843865757054, 0.05815458398365894, 0.04775120951886244, 0.06085329230266022, 0.08637147382391522, 0.11422368839534411, 0.14094792137560538, 0.1654822214423985, 0.18763714302223447, 0.20758152715004285, 0.22560676739170993, 0.24200044388220884, 0.2569852904387188, 0.27070359485872875, 0.12968992495339768, 0.1064308187917943, 0.08494418449426486, 0.06646882556676263, 0.0521588049567378, 0.042017866680877994, 0.0337134363298024, 0.023912473410222016, 0.012023157613990969, 0.009792873697641554, 0.020275941572368852, 0.02707758110884089, 0.027882453642540612, 0.02320427696358478, 0.014983802567068683, 0.007794073658071061, 0.006260403387201363, 0.0046692786344811705, 0.007072344938683671, 0.010495803147738951, 0.0077316637971053224, 0.008165040503054685, 0.026760546774490093, 0.051041695201569086, 0.07728395208866627, 0.10299859011371518, 0.12630291713835484, 0.14582734346485762, 0.1606308520172995, 0.1701155111992639, 0.1739504955224518, 0.1720156343919592, 0.1643744333495826, 0.1512894250006607, 0.13330376458452542, 0.11145152803801378, 0.08779449653797998, 0.06686968653918611, 0.05791340342036391, 0.06792891805331862, 0.08987550975169224, 0.11522451061856259, 0.140207658743081, 0.1635055179374173, 0.18480311370158484, 0.20420440816750238, 0.22195523963706612, 0.23829866030779254, 0.2534089196877213, 0.2673779927153625, 0.127453427768969, 0.10539582492749341, 0.08572379118240629, 0.06952715885034251, 0.057371878563264055, 0.048343937538037896, 0.03974437612859218, 0.02870716357118188, 0.014465139743142647, 0.003416416761142514, 0.015206366086116418, 0.022928469017214806, 0.024814684076062632, 0.02128406978180214, 0.013781013718415263, 0.006593509407863286, 0.006164833995608486, 0.006718432711319331, 0.008875706012698919, 0.010852176911965798, 0.007393673931092081, 0.009349062409296874, 0.02799977462063222, 0.05204100303239059, 0.0779738616483802, 0.10337114641872706, 0.12638468927858204, 0.1456709448974607, 0.16031432735445372, 0.16974524403624866, 0.17366554389780797, 0.17199292392874857, 0.1648357959288995, 0.15251338260405678, 0.13564703150915844, 0.1153834508641628, 0.09390844338795323, 0.07554881202839299, 0.06764677390532514, 0.07525703346282595, 0.09386933084379306, 0.1165863462970015, 0.13964927746210004, 0.1615605768663887, 0.18189282236436205, 0.2006834597117499, 0.2181268530429383, 0.23441362796208845, 0.24966099897580477, 0.26390274453113083, 0.12497797529651433, 0.10413559844503628, 0.08629783549701865, 0.0723244820861514, 0.062151601491650124, 0.054159568741295294, 0.04555301435923029, 0.033975108973237314, 0.019105218731433785, 0.0032721195262937867, 0.010374275178234587, 0.018608857889733103, 0.021556875931989582, 0.019217341692090256, 0.012334254980704906, 0.004653623757248988, 0.006108261359891553, 0.008732057121026477, 0.01075117511395315, 0.011211690919878762, 0.006613043368562752, 0.01037963191804319, 0.02946358413984193, 0.05334788444070624, 0.0789604095588432, 0.10399552655096797, 0.12666361379581914, 0.14565869713433577, 0.16009728282112007, 0.1694428597704817, 0.1734338664325938, 0.17202908682349904, 0.1653837202332194, 0.15387230592978882, 0.13818443009283068, 0.11954548247674257, 0.10016894698490439, 0.08401704214889036, 0.07690874849912903, 0.08258964770490552, 0.09815738362949215, 0.11820059877460014, 0.13920790380398546, 0.15960210901316635, 0.17887091823233597, 0.1969902449494231, 0.21409953149743538, 0.23032951958839634, 0.24573145891556547, 0.2602725679871778, 0.12220115055525442, 0.10256478013485268, 0.08656031067423946, 0.07475188649220295, 0.06644129106892448, 0.059471229420456635, 0.05108642757908885, 0.03940402540214032, 0.024585204436587054, 0.009370481715356331, 0.006229035409455388, 0.01405739602505885, 0.018146488102734365, 0.01713734657958062, 0.010938835919946295, 0.0022081607651690325, 0.006519024082207682, 0.010668184456525159, 0.012515079390952939, 0.011534617659737591, 0.005399720509666375, 0.011357055981569542, 0.03108248730471068, 0.05488803153558327, 0.08018320479830907, 0.10482374998516274, 0.12709999218032814, 0.1457553762457249, 0.159945845703391, 0.16917325441977143, 0.1732167913907408, 0.1720793284756857, 0.1659637519140213, 0.15529634303243534, 0.14082123433834873, 0.12380556900273519, 0.10640996162003923, 0.09216063766847897, 0.08566646004730417, 0.08975806816404575, 0.10257203379367157, 0.11996229382919056, 0.13881812141608316, 0.15758395516629256, 0.17570131136293937, 0.193095886555623, 0.2098512349791291, 0.2260310812379549, 0.24161123942915785, 0.2564834299930839, 0.11906657269650851, 0.10060808505290796, 0.08642573057284042, 0.07673487192215091, 0.07021383801734449, 0.06429195549553762, 0.056320197128064756, 0.04482486651541879, 0.030314838819794975, 0.015397079528315694, 0.004975902978444652, 0.009236245101460998, 0.014743422224822231, 0.015311685890330261, 0.010105359117256574, 0.0018259871224188481, 0.007693511174987466, 0.012514584885813881, 0.014070063337403625, 0.011794875723371828, 0.003855715207141515, 0.01245901590606303, 0.03283491744460856, 0.05660530981467063, 0.08158771463104675, 0.10580917673355089, 0.1276539198321133, 0.14592507355270684, 0.15982532898274254, 0.16890048354958706, 0.17297484684810466, 0.17209824777596164, 0.16652141587825786, 0.15671720246418322, 0.14346848070115645, 0.1280481547272867, 0.11250240647350819, 0.0999020127597684, 0.09389415683259984, 0.09664589495583589, 0.10697468889203773, 0.12177403497958302, 0.13841618229450084, 0.15546027575060248, 0.1723478528573703, 0.18897150797903578, 0.20536031999960297, 0.22150397759202023, 0.23729261863523404, 0.2525328332890704, 0.11552492770135733, 0.09820100513260564, 0.08582829452733393, 0.07822695541151732, 0.07346302667545807, 0.06864065242577748, 0.0612454144756436, 0.05014219893198807, 0.036051587478375544, 0.021282225537972984, 0.008198376080543789, 0.004168541754869761, 0.011762683313343203, 0.014155349657884201, 0.010407037499094085, 0.00503284123850509, 0.009578694578128958, 0.014260096893008419, 0.015358923030649629, 0.011969451959082816, 0.0023270186835114017, 0.013853674709279722, 0.03472504976764271, 0.05845901900308142, 0.08312627188236299, 0.10690783281930293, 0.12828636230900417, 0.1461320291630878, 0.15970091196936625, 0.16858837553255285, 0.1726683878160709, 0.17204057097512787, 0.16700317169878257, 0.15806943375146518, 0.14604440089799972, 0.13217404514320996, 0.11834632346014479, 0.10718650888208943, 0.10157203514184532, 0.10317180109470868, 0.11125374621021301, 0.12354855094004168, 0.13794188559167142, 0.15318666648284193, 0.16877499494656029, 0.18458867169627727, 0.20060591549445625, 0.21673516738122842, 0.2327695739139503, 0.24842012665351748, 0.11153477648431084, 0.09529003861036181, 0.08472079464372921, 0.07920505917721901, 0.07619871215367055, 0.07254173112542625, 0.06586306116276239, 0.055301072203695456, 0.04168804936284532, 0.027033123744082243, 0.013007993641926285, 0.0016985962506954528, 0.01009329188458695, 0.014119463895174662, 0.01202572631489126, 0.00869302787794096, 0.011924240779991782, 0.015885533651375395, 0.01634292071153005, 0.012020545783947064, 0.0020827262367943493, 0.0156205375420818, 0.036759689496672056, 0.06041814547809631, 0.08475749777735661, 0.10807904084527205, 0.12895993004967113, 0.14634132585874918, 0.1595382446272139, 0.1682010869094252, 0.17225815733575778, 0.17186178482641468, 0.16735718766607058, 0.1592913478641841, 0.148475144269629, 0.13609931796039057, 0.1238644761835678, 0.1139750919923095, 0.10868562485401903, 0.10927882807332163, 0.11532133062157374, 0.12521009640711644, 0.13734010311734404, 0.15072117838062754, 0.16494841747883046, 0.17991980657055034, 0.19556831331431745, 0.21171331261141862, 0.22803817855740066, 0.24414683929421482, 0.10706321747530748, 0.0918326153754304, 0.08307368452137212, 0.07966647731033501, 0.07844412952232849, 0.07602495021568192, 0.0701814347633863, 0.06027107745426988, 0.04717559055600733, 0.03266533898102797, 0.018278505111834896, 0.007071706874004916, 0.0107735745513412, 0.015401412348863825, 0.014633939368534922, 0.01244001080955473, 0.014483109401771456, 0.017364122871319405, 0.016993847087754112, 0.011885421825561515, 0.0035727115677394107, 0.01772617003077494, 0.03893178174678388, 0.062455264509430855, 0.08644485645710391, 0.10928551983467291, 0.12963937815417606, 0.14651943971346107, 0.1593039673676097, 0.1677035920163659, 0.17170577465826445, 0.17151866462291862, 0.16753393979989736, 0.1603256267026026, 0.1506949896960081, 0.13975383380478262, 0.12899744847003206, 0.12024013234057385, 0.11522542364140821, 0.11492770905588993, 0.11910990434230846, 0.12669502507875532, 0.13656197657723446, 0.14802523693076416, 0.16083561296239593, 0.17493861846137895, 0.19022937466270765, 0.20642922758901458, 0.22309703850523924, 0.2397170398096374, 0.10208650000011162, 0.08779686230405778, 0.0808746103657297, 0.07962716417035992, 0.08023443259833625, 0.07912536133898417, 0.07421485276559604, 0.0650379572422571, 0.052493940643637035, 0.03819159148995395, 0.023754861309228215, 0.012813421258837552, 0.013648054220254318, 0.017797873800840597, 0.0177892100954958, 0.01612145857315496, 0.017066020290060307, 0.018667304037570893, 0.017295259085148444, 0.011482313443948799, 0.005421354761816896, 0.020061817464135007, 0.04121404571467649, 0.06454198910234428, 0.08815504251054807, 0.11049317241709353, 0.13029189190652748, 0.14663466175827725, 0.1589661482375805, 0.16706210611180033, 0.17097415015152384, 0.17096970066809572, 0.16748665317631847, 0.16111968204339852, 0.15264622282614193, 0.14307967662409224, 0.13370000187353365, 0.12596285971450288, 0.12118665873512478, 0.12009264051163235, 0.1225692365237193, 0.1279518298439854, 0.1355658411941458, 0.14506447007924225, 0.15640642797407353, 0.16962048033678578, 0.18457295667447518, 0.2008763766956884, 0.21794777486727404, 0.23513771965345173, 0.09659071263463873, 0.08316133032843376, 0.07812866827379376, 0.07912112362131611, 0.08161594549988817, 0.08188326137120364, 0.07798284651348121, 0.06959856941642739, 0.057636832435570676, 0.04361687705271522, 0.02932802738262772, 0.018632540367010276, 0.017721909672474206, 0.02091705117455433, 0.0211603150230224, 0.019623146464453577, 0.01953474387189936, 0.019772061044241993, 0.01724982080091503, 0.01072910465761417, 0.007184039214424195, 0.022499125164178436, 0.0435617778832344, 0.06664680854852453, 0.08985671380769174, 0.11167076786892158, 0.1308872322642823, 0.1466574160998214, 0.15849464692079804, 0.1662444468246471, 0.17002783162509072, 0.17017543225119955, 0.16717160904814768, 0.16162582527989033, 0.15427881768752202, 0.14602969892688164, 0.1379384054493677, 0.13113177122908443, 0.12656912310695048, 0.12475855244589855, 0.12566389023600782, 0.12894088529866501, 0.13431794536655978, 0.14180946759769728, 0.15163356425284621, 0.16394280019576854, 0.17858536706366793, 0.19505143367641925, 0.21259555916301806, 0.230419200171936, 0.09057272212083206, 0.07791479573858077, 0.07485969383926841, 0.07820071829563278, 0.08264578533077108, 0.08434406133594906, 0.08150948649922968, 0.0739574642923113, 0.06260430567337881, 0.04893690906791218, 0.03491876328064899, 0.02442882482036612, 0.022293970405648997, 0.02440427777490098, 0.024525998462782715, 0.022853192150874585, 0.021788960464743164, 0.020666552938797825, 0.01688952696160504, 0.009565546883614598, 0.008770912922903598, 0.024927869053940687, 0.04592083098078769, 0.06873519691700503, 0.09151982446039057, 0.11278967781827237, 0.1313978116591561, 0.14656050421511427, 0.1578614195763556, 0.16522034270364505, 0.16883329029619168, 0.1690987015351991, 0.16654834349410957, 0.16180130395819028, 0.1555500249790725, 0.1485662510607479, 0.14168849056711857, 0.13574160564359763, 0.13137706064330312, 0.12891931155616132, 0.1283712260050395, 0.12963406185672943, 0.13279304034188597, 0.13823650577237998, 0.14649304823835402, 0.15788536705283815, 0.17225585981140376, 0.18895492012823487, 0.20704970930480907, 0.2255755608035759, 0.08404164167095574, 0.07205626519844423, 0.0711130177531804, 0.07693771848629892, 0.08339158300756126, 0.08655799011191843, 0.08482268853292096, 0.07812438220027546, 0.06739844391970755, 0.05413885769280454, 0.040456314604582294, 0.030115651338835946, 0.0269975870442552, 0.027999042535269997, 0.02773416193257001, 0.025737629656416055, 0.023756190892665008, 0.021351886535345733, 0.016285019158057048, 0.007972833776919963, 0.010202578084144317, 0.027270572828788628, 0.04823634114042745, 0.0707712608698928, 0.09311557576140773, 0.11382375231710137, 0.13179875503612845, 0.14631930397707113, 0.15704078055113668, 0.16396170009700184, 0.16735915679393232, 0.1677048412897537, 0.16557976289867013, 0.16160825294817222, 0.15642393836577004, 0.15066011988607578, 0.1449342405685458, 0.13979267024298156, 0.13561908698067182, 0.1325765172068957, 0.13067985743353716, 0.1300143231534784, 0.1309749115557637, 0.13432828237345612, 0.14096468360001374, 0.15143067707368857, 0.1655771919230728, 0.18259194723051322, 0.20132435503162444, 0.22062508365498285, 0.0770213221237879, 0.06559538449159937, 0.06696034572539544, 0.07542483593662976, 0.0839310417754786, 0.08857956239951345, 0.0879534551160795, 0.08211240049199292, 0.07202121289438687, 0.05920346893215336, 0.04587507596918359, 0.03561446491157871, 0.03162435515424908, 0.03151632251208308, 0.030674825058143534, 0.028217732061922525, 0.02538414821748993, 0.02183913030824067, 0.015548822916271372, 0.005992427828365087, 0.011555412519222444, 0.029481937007956007, 0.050459271897643404, 0.07272001697071728, 0.09461684108072631, 0.11474935837006073, 0.13206798058375246, 0.1459119471936688, 0.15600963702652668, 0.1624428408363439, 0.16557641869557294, 0.1659618105762243, 0.1642321995035595, 0.16101359940288604, 0.15687108659257332, 0.15228967505042906, 0.14766677637995823, 0.14329039743515093, 0.13930813806809644, 0.1357386815282065, 0.13258847681985905, 0.13007537340579897, 0.12885691745372613, 0.1300747191636308, 0.13503250828305882, 0.14456424377816415, 0.15854627154770476, 0.17597309291650454, 0.19543918126963428, 0.21559070603617395, 0.06955482125294403, 0.05855364635356066, 0.06250773624296194, 0.07377729751189245, 0.08435105993889787, 0.09046675607536386, 0.09093505645750415, 0.08593660908679329, 0.0764736865084591, 0.06410779035991071, 0.05111526157578641, 0.04085543079783974, 0.03603847947206554, 0.034821843351047446, 0.03326571343399138, 0.03024781117783757, 0.026634494046129248, 0.022142051153598127, 0.014824716605459892, 0.0037704246365347924, 0.012920820617239212, 0.03154058106354145, 0.05254978818194395, 0.07454954725788306, 0.09599885010783767, 0.11554555414410166, 0.1321863145628997, 0.14531949302701688, 0.15474771144548585, 0.16064072363776546, 0.16345859144435257, 0.16384029175865134, 0.16247542742369453, 0.15998895281988604, 0.15686808282184125, 0.1534402095386554, 0.14988363922576395, 0.14624505805994806, 0.14246144075618128, 0.138420661758027, 0.1341049703784338, 0.12982138778421246, 0.1264425940238601, 0.12547390497544308, 0.12868528731165393, 0.1372748982708435, 0.15116494320286095, 0.1691154570047099, 0.18942025591826597, 0.21050046720543858, 0.06171284453742964, 0.05096732248353785, 0.057907932018021475, 0.07213366766751722, 0.08474613396741883, 0.09227986632184743, 0.0938021756319231, 0.08961323190624221, 0.08075617557698207, 0.06882796102727498, 0.05612434364119023, 0.04577855873846154, 0.0401430911173715, 0.037815765798627096, 0.03544467514715533, 0.03179338869441172, 0.027477737371097193, 0.022267541977390753, 0.014254586073219956, 0.0019033637317952927, 0.01436207619217091, 0.033438163560178674, 0.05447788652069858, 0.07623259913411923, 0.09723992384796706, 0.1161943448878981, 0.13213763868491857, 0.1445261082431291, 0.15323776484045115, 0.15853516219259678, 0.16098187445668127, 0.16131376095174726, 0.16028265648730716, 0.15851050522124044, 0.15639735207258096, 0.15410345817125676, 0.15158830094044323, 0.1486715863687302, 0.14510050026385934, 0.14064325802640396, 0.13524575036436834, 0.12926683338248154, 0.12374637407907882, 0.1205332743390825, 0.12191708778645359, 0.1295550881669935, 0.1434409798151343, 0.16204394942355008, 0.18330094347827378, 0.20538792803363579, 0.05361059893098986, 0.04289460422761928, 0.05337800062188609, 0.07065463426943269, 0.08521578478119637, 0.09408003537910813, 0.0965900469064898, 0.09315911103183229, 0.08486889070016984, 0.0733417456536796, 0.06085842057165797, 0.05033466981111015, 0.04386656569667725, 0.04042328286802108, 0.03716552686870713, 0.03282984821246689, 0.027889489809234495, 0.02220689413548326, 0.013924622686578243, 0.002604464654708824, 0.015883106026601656, 0.035169554661209905, 0.056222362062210936, 0.07774750706699027, 0.09832210363319754, 0.11668095930871461, 0.1319090583000289, 0.1435192599677409, 0.15146583255766788, 0.15610905301451866, 0.15812530411976428, 0.15835854251931247, 0.157630518442314, 0.15655896201416664, 0.15544695170408313, 0.15427727902815283, 0.15278985317766264, 0.1505894874927689, 0.1472510988730096, 0.14243291611023193, 0.13603523903777, 0.12843636728020072, 0.12079445782828227, 0.11527114798268494, 0.11472800826170994, 0.1214011881148175, 0.13538938941301046, 0.1547928810156126, 0.17712289562528133, 0.20029253205992995, 0.04544349362063024, 0.03443470918145498, 0.04922061350149003, 0.06951799088167832, 0.0858608530754815, 0.09592749851504924, 0.09933361415026168, 0.0965914630090417, 0.08881285664685958, 0.07763065867587517, 0.06528331681117741, 0.05448616485964257, 0.047156569253932454, 0.04258928182322525, 0.03839565936881271, 0.03334167938628737, 0.027848412307773063, 0.02193119768131262, 0.013818220610063292, 0.0047483100974343145, 0.017425566865450298, 0.03672670135560357, 0.05776924731374008, 0.0790785236188057, 0.09923158327365508, 0.11699409217942369, 0.13149107526099285, 0.1422899230776274, 0.14942148279391373, 0.15334862662138035, 0.1548709155317274, 0.15495385671985812, 0.1544990577225355, 0.15411952159977177, 0.154010497456437, 0.15396548599831666, 0.1535028411642452, 0.15202280702802975, 0.14894329889794047, 0.14382148966462882, 0.13650544453271807, 0.12736477798977577, 0.11762585143025206, 0.10971880549354492, 0.10712518073364201, 0.11281384230241749, 0.12703420623778386, 0.1474079402047321, 0.17093709113210973, 0.19525986316744634, 0.03756645369094582, 0.02578826664299206, 0.04583842762132603, 0.06890803312369219, 0.08677871869499497, 0.0978796362562448, 0.10206673254266672, 0.0999278144988028, 0.09259086948960929, 0.08168162692118121, 0.06937539654489638, 0.0582076426651888, 0.049977341401399915, 0.04427525719219864, 0.03911458086331581, 0.0333223528856583, 0.02733604980274664, 0.021392792323659874, 0.013813431851328982, 0.006800290603506139, 0.01889264622552176, 0.03809738029930857, 0.059110546961599085, 0.08021573245002973, 0.09995891054529575, 0.11712607368957711, 0.1308777496859122, 0.1408328026506678, 0.14709810809529417, 0.1502437369198095, 0.15120392558225038, 0.1510818682120308, 0.15087173725948172, 0.15118192137082645, 0.1520872078589976, 0.15317782447471343, 0.15374721714558978, 0.15300014676795531, 0.15021144094754127, 0.1448460243461745, 0.13669557066847463, 0.12609691440424575, 0.11429355592348221, 0.10392331847614734, 0.0991242494559393, 0.10379837374495611, 0.11841103826008931, 0.1399486458599225, 0.1648048661152924, 0.19034173903719198, 0.03066655598622445, 0.01749958873378815, 0.04371270696335959, 0.0689987543695308, 0.08805780569405057, 0.09998897238102894, 0.10482143375422599, 0.10318603018848144, 0.09620835086044337, 0.0854881937906125, 0.07312211497683761, 0.06148641696481244, 0.052308499165048525, 0.04545751775718028, 0.039312963599562094, 0.032774760708153126, 0.026338478811061616, 0.020532433598171102, 0.013727841576146694, 0.008435813231869092, 0.02018205259976598, 0.03926830576187782, 0.06024362753253249, 0.08115470138686272, 0.100498962150792, 0.11707294301979854, 0.1300668384530413, 0.1391465717869455, 0.14449326062046985, 0.14678820609123927, 0.1471129517128597, 0.14672774198957203, 0.1467354689112942, 0.14774056961397755, 0.14968208236530153, 0.15193008585418738, 0.15354839437074566, 0.15355471198220957, 0.1510941257461576, 0.14554852966426213, 0.1366516018619512, 0.12468752039325451, 0.1108658292416142, 0.09795143882191437, 0.09075169817178222, 0.09436532477228547, 0.10957081338596825, 0.13249135270859988, 0.1587988261846303, 0.1855960617978604, 0.026033708080730182, 0.011622678818542613, 0.04330539010738645, 0.06993299207630105, 0.08977206379960094, 0.10230129442739135, 0.1076272727474118, 0.10638435829623984, 0.0996740046381182, 0.0890512893355722, 0.07652232664709706, 0.06432296028657963, 0.05414467439063282, 0.04612623286579089, 0.0389919410596661, 0.0317120442529844, 0.024849422647995056, 0.01929000299709708, 0.0133750665450543, 0.009512563017523974, 0.021213589671804443, 0.04023073409739357, 0.06117117148048199, 0.08189596598622197, 0.10085071547348394, 0.1168344193927366, 0.12905990361991942, 0.13723412612897265, 0.14160904350546816, 0.14298024625467626, 0.1425902839778433, 0.1418797125060868, 0.14208067816668313, 0.14379478749936964, 0.1468062331260356, 0.15024435938828187, 0.15293738492987854, 0.15372437463862001, 0.15163416430629983, 0.14597570503030174, 0.13642580157347187, 0.12320086337839153, 0.10742734444483946, 0.09189488337378698, 0.08204873781971642, 0.08453125821165174, 0.10058544941786646, 0.1251328208070366, 0.1530034599632622, 0.18108633068405308, 0.025380859674536155, 0.013169092133418693, 0.04489268213379927, 0.07180306217092446, 0.0919763307083743, 0.1048540851186815, 0.1105107726649865, 0.1095414356955864, 0.1030002203071113, 0.09237959336693993, 0.07958635041235324, 0.06673127121472695, 0.05549569828285105, 0.046285149476332964, 0.038162509966099996, 0.03015852942940664, 0.022874328502902944, 0.017616099343526787, 0.012603464414483307, 0.009961219689438142, 0.02194735289684383, 0.04098623199941444, 0.06190129486185758, 0.08244436020924163, 0.10101684760937314, 0.11641377708596201, 0.1278623898402956, 0.13510285795948862, 0.13845257290929108, 0.13882298520132597, 0.13763223367550453, 0.1365291713827796, 0.13690141422447452, 0.13934919371740723, 0.14347739676739205, 0.1481494214264693, 0.15195100412362259, 0.15355173389382487, 0.15187847711910724, 0.14617858564583286, 0.13607605987336155, 0.12171001452590231, 0.10407991336220253, 0.0858772983823725, 0.07307819276797783, 0.07432010303595417, 0.09155662866238172, 0.11799418834457802, 0.14751517799703423, 0.17688071122921026, 0.029253830187339062, 0.02093167937902208, 0.04844955055230092, 0.07463977279540257, 0.09470343847414588, 0.10767543007615092, 0.11349498197080589, 0.11267621328036682, 0.10620319608410927, 0.0954895129924178, 0.08233576648757784, 0.06873912104640989, 0.05638719575260097, 0.04595198847158308, 0.03684499348387396, 0.028150406290928486, 0.02043491764776353, 0.015482616482850967, 0.011314028630308165, 0.009781136832656516, 0.022393766819757542, 0.04155054239645899, 0.062447314783606975, 0.08280816539941682, 0.10100319575253039, 0.11581764165885054, 0.12648367536710783, 0.13276495417522352, 0.13503652792480875, 0.1343251321948497, 0.13223959117173734, 0.13067077934206975, 0.13119552000865445, 0.13441427798883201, 0.13972066077765682, 0.145681261262287, 0.15063212009906, 0.15308415016833518, 0.15187791846178056, 0.14621207285971838, 0.13566502534264918, 0.12029561428550814, 0.1009422337598961, 0.08006280999918083, 0.06393744695535934, 0.06376573005904036, 0.08262952577568532, 0.11122481382414943, 0.14244139297881522, 0.17305055951847795, 0.03637609954380788, 0.030670961009442062, 0.05369895957188251, 0.07841390257952996, 0.09796358773881132, 0.11078350988295571, 0.11659915437178368, 0.11580778084079814, 0.10930277657731333, 0.0984047889844397, 0.08480289807368628, 0.07038808542370827, 0.05686147711803733, 0.04515964977967922, 0.03506866644707265, 0.025735744079147135, 0.017573992664731017, 0.01289193378371732, 0.009467309430944376, 0.009061810483599119, 0.022616310408835827, 0.04195412089512268, 0.06282673425882508, 0.08299804847333339, 0.10081811961109684, 0.11505573359690167, 0.12493710575933735, 0.1302377229830416, 0.13137980789666917, 0.12950183200281615, 0.12641824083852152, 0.12430260920103242, 0.12496488340196764, 0.12900723124743713, 0.13556944868295784, 0.14288373814732222, 0.14902991974683105, 0.15237372232680826, 0.1516869973773283, 0.14613431387696696, 0.13525896209171537, 0.11904395362655033, 0.0981478841062266, 0.07466491527940017, 0.054784282404099736, 0.05291762277745165, 0.07401403781642074, 0.1050047597984074, 0.1378981694723547, 0.16966832843534999, 0.045297629977576956, 0.04107831897959896, 0.06026399486550029, 0.08304865178696799, 0.10174598605840893, 0.11418670463023083, 0.11983855692180083, 0.11895508813478424, 0.11232201718037667, 0.10115574226702481, 0.08702991364924398, 0.07173320868115002, 0.05697855243083884, 0.04395843036589174, 0.032871870239367974, 0.02297345218423758, 0.014361142247170116, 0.009887246391171054, 0.007092553072672739, 0.008037720380778086, 0.022725366689587162, 0.0422386885817906, 0.06305924228224945, 0.08302580399708535, 0.10047181894203135, 0.11414059319249692, 0.12324002246516262, 0.12754395297188872, 0.12750831771681254, 0.12437577185082677, 0.12018000614111807, 0.11742632952843471, 0.11821580336655836, 0.12315313399823609, 0.1310668177861282, 0.13980935325165691, 0.14720014970799425, 0.15147716928039012, 0.1513634631803984, 0.14600589891753551, 0.13492628824579567, 0.11804423778637503, 0.0958406427082272, 0.06995182433532246, 0.04589119094176393, 0.041855558998449886, 0.0660156588233249, 0.09954362008487583, 0.13400596989969765, 0.16680484533491707, 0.05515641259666023, 0.05176669481813232, 0.06778866088633488, 0.08843736362979505, 0.10602224578436771, 0.11788425593812868, 0.12322440552044063, 0.12213657411131937, 0.1152865029507021, 0.10377817612552556, 0.08906748208430498, 0.07284209191087403, 0.056816948082649484, 0.04241945250369082, 0.030303300172296654, 0.01993095991603419, 0.010903143300120452, 0.006579388922502895, 0.004342508008548903, 0.0071905554147392034, 0.022859791434397606, 0.04245002772755252, 0.0631638376608199, 0.08290298749321279, 0.0999756761938566, 0.11308732661496833, 0.12141379952998746, 0.12471230420010292, 0.12345589945889701, 0.11897862752221507, 0.11354383959334234, 0.11004744421307074, 0.11095952740011024, 0.11688665683070888, 0.12626712950847224, 0.1365200999871418, 0.14520527433093497, 0.1504555685620641, 0.15096772174789005, 0.14588885197718385, 0.13473578151661608, 0.11738499553743695, 0.0941663594785683, 0.0662398735813116, 0.03776100250450645, 0.030736438880633564, 0.059072392256066954, 0.0950722188381986, 0.1308832046199914, 0.16452605119227495, 0.06550082620744653, 0.06256986481948855, 0.07598480100348526, 0.09446051438833303, 0.11075075210823639, 0.12186736504914593, 0.1267639206091331, 0.12536972867742932, 0.11822346468159256, 0.10631196348333644, 0.09097292841380601, 0.0737931586980438, 0.05647377796059727, 0.04063930999005673, 0.027425708487645188, 0.016680849987315068, 0.0073790458653748585, 0.0033360439539193436, 0.002131304988465924, 0.007244542760400581, 0.02315455617739845, 0.04262824712717476, 0.06315549691305843, 0.08263960544482316, 0.09934171111983664, 0.11191341688721407, 0.11948390015847098, 0.12177772272950843, 0.1192654199456372, 0.11335296086720283, 0.10653754256738855, 0.10217561444065532, 0.1032130596262167, 0.11025450831368984, 0.12123814784390528, 0.13308832154372843, 0.14311447075800884, 0.1493738966993925, 0.1505620510800471, 0.14584540596361145, 0.13475448216725694, 0.11714976189112451, 0.0932613180501947, 0.06386267535800906, 0.031340450093385375, 0.019995077021254345, 0.05377264462075339, 0.09182347843920459, 0.1286377452792275, 0.1628894213541381, 0.07608205966582228, 0.07339238768254482, 0.08463336490496161, 0.1009984851522023, 0.11588120261993592, 0.1261205691129593, 0.13046049018048358, 0.12867062039776408, 0.1211607492963019, 0.10879937177754075, 0.09280787973180549, 0.07467286551036824, 0.056063246946700306, 0.03874535202898189, 0.0243241984630157, 0.013297714693386085, 0.0042408149629956215, 0.002708215616447525, 0.0038505325329152547, 0.008610197212778272, 0.023700756522193438, 0.04279768554809984, 0.06304203616219416, 0.08224308599910053, 0.0985822450335123, 0.11063864341883087, 0.11747995998514711, 0.11878185594265776, 0.1149900029617634, 0.10755470759248331, 0.09920032026270446, 0.09382511247301904, 0.09500042241112865, 0.10331898913869952, 0.11606359081313372, 0.12959745042034332, 0.14100335672719186, 0.14830031212942382, 0.15020959267032366, 0.1459365751547091, 0.1350453813222515, 0.11741237776295779, 0.09323837823041645, 0.06310867483793593, 0.028155760497891865, 0.011593590728627846, 0.050785721261668235, 0.0900013813992738, 0.1273572734906569, 0.1619404207739995, 0.08674980419251066, 0.08416860909734807, 0.09357062270444627, 0.10793941149721654, 0.1213587137350994, 0.13062323398526313, 0.13431392301503786, 0.13205342857289984, 0.1241257143997313, 0.11128320806507407, 0.0946354604943566, 0.07557172437697392, 0.05571256114076476, 0.03689968320691559, 0.02112291181431791, 0.009858789935958335, 0.003306673466062312, 0.00585053309516877, 0.00731183685056052, 0.01095548311193638, 0.024514324375609027, 0.04295907886622999, 0.0628218935494526, 0.081717773563032, 0.09770987148581046, 0.10928514815072218, 0.11543589483656397, 0.11577342413205481, 0.11069435309567165, 0.1016564086920866, 0.0915866856618317, 0.08501550535322709, 0.08635472525064058, 0.09616319124024598, 0.11084607427876061, 0.1261424271373734, 0.13895332354696677, 0.14730512464947385, 0.14997311096097984, 0.14622056707228595, 0.13566504470962298, 0.11823245992703967, 0.09417376386214972, 0.06414291869227608, 0.029511554183666244, 0.012698010119821388, 0.05063159672116569, 0.08974365484123925, 0.12710010486195672, 0.1617094388857514, 0.0974049268270397, 0.0948485635097777, 0.102673584233389, 0.11518302120422065, 0.12712715844956335, 0.135351024279705, 0.13832077273489232, 0.13553001894353875, 0.1271441257506988, 0.11380489860101707, 0.09651718842477629, 0.07657922166784514, 0.055554331858249505, 0.03529757838664491, 0.01801622917083316, 0.006460141464010542, 0.005572171096322221, 0.009474684631715118, 0.0109370938833303, 0.013741364281703004, 0.025529534313045762, 0.04308617309996212, 0.062483451046544625, 0.08106516155328615, 0.09673781391727047, 0.10787767370568449, 0.11339001674857482, 0.11280847273001444, 0.10645604325026353, 0.09575130862123056, 0.08377258836085777, 0.07577277707132594, 0.07732176382671493, 0.0888986136689652, 0.10571019826039078, 0.12282949607532076, 0.13705033337573877, 0.14645941036540364, 0.14991353755498288, 0.14675110904358374, 0.13666137401899572, 0.11965171204930891, 0.09609816914330291, 0.06695666866566949, 0.03500556919007791, 0.022082165600369366, 0.053392798651881346, 0.09109159566497509, 0.1278885471952199, 0.16220965509395674, 0.10797730939816849, 0.10539217156335963, 0.11184859321979383, 0.12264180657590978, 0.13313163880173706, 0.14027724871854813, 0.1424747127948086, 0.13910959882432478, 0.13023913919122115, 0.11640264248311034, 0.09850981854742823, 0.07777803700270512, 0.055715311770535306, 0.03415337625384962, 0.015318692534602798, 0.003331006826058033, 0.008546021175561573, 0.012958588288330271, 0.014423660666543714, 0.01657677336677647, 0.026618211892186293, 0.043127649441789595, 0.06200625420193478, 0.0802850053475305, 0.0956807185035996, 0.10644397817403128, 0.11138512270464425, 0.10995038917194234, 0.10236651543501421, 0.08995829463411573, 0.07586525871101761, 0.0661313688731475, 0.06796672287321569, 0.08167617328365126, 0.10080516390841235, 0.11977497175386652, 0.13538304923267686, 0.14583326180077302, 0.15008834900200305, 0.1475757963047392, 0.13807173262653577, 0.12169169345207917, 0.09899497083617545, 0.0713808412317004, 0.04312468567435234, 0.033398577761709465, 0.058670465404385565, 0.09398153411869317, 0.12970653102905877, 0.16343617933388677, 0.11841479301845376, 0.11576646661845426, 0.12102323105002993, 0.1302406852536513, 0.13932015606379053, 0.14537401963813765, 0.14676694357320666, 0.14279848023397548, 0.13343044329342946, 0.11910978955715626, 0.100662455593383, 0.0792383106557296, 0.05630282476359328, 0.033667813456811184, 0.013501726731018232, 0.002053002071337545, 0.011377717437687928, 0.016113133266425606, 0.01760353296894319, 0.01920163868067825, 0.02762045101038496, 0.04301365682942626, 0.061364166268122654, 0.07937735832759402, 0.09455588384383266, 0.10501540200744666, 0.10946849661783473, 0.10726952249795209, 0.09853136584800253, 0.08442723864726852, 0.0680192145321883, 0.056138354845286495, 0.05838766492782339, 0.07470143308072158, 0.09630571201674396, 0.11710250101768702, 0.13404021383253598, 0.1454937109584864, 0.15054986321152955, 0.1487345908204753, 0.13992164530256845, 0.12435341661516398, 0.10280589962144673, 0.07715094796862816, 0.05265815901416978, 0.04518553052985447, 0.06583727060304043, 0.0982623522022896, 0.13250215491876355, 0.1653666075647985, 0.12867726804986387, 0.12594407861672208, 0.1301407425421427, 0.1379159380135697, 0.14564462044976986, 0.1506132015253015, 0.15118661476144613, 0.14659996947719528, 0.13673362500454025, 0.12195358201374437, 0.10301427351447104, 0.08101293059824291, 0.05739205308455401, 0.0339812813220018, 0.01306359934885462, 0.004252266011597719, 0.013838557201165617, 0.018813818362389156, 0.020346195928043213, 0.021430919789152323, 0.028371868576000252, 0.04266522411114106, 0.06053022226430637, 0.07834546873005772, 0.09338487169373116, 0.10362752564487417, 0.10769173888566287, 0.10484220307547659, 0.09506926619857298, 0.07934338957463788, 0.06046196394147394, 0.04586325616388355, 0.04874512937186157, 0.06825333120500757, 0.09240938192356153, 0.11493839141168535, 0.13310729262068327, 0.14550242555276527, 0.1513435731738764, 0.15025860525560097, 0.14222421905471508, 0.12761877566572677, 0.10744194022644594, 0.08397864909937801, 0.06292457296348873, 0.057088138933771855, 0.07429818846233936, 0.10372957832102378, 0.13619438274047377, 0.16796288549720828, 0.138733290723819, 0.13590229583925492, 0.13915620221492936, 0.14561389092240193, 0.15206136181764235, 0.1559671504551894, 0.15572124875294344, 0.1505143899454341, 0.14015979895021766, 0.12495436497271295, 0.10559312518543383, 0.08313476171165642, 0.05901820296485181, 0.03513531094086114, 0.014132115852570163, 0.0068954616812745, 0.0158034231140065, 0.02096016205854569, 0.02254442983811718, 0.023125168438795175, 0.02872117828115255, 0.042004746324307694, 0.05948281167998354, 0.07719937981082312, 0.09219537782038988, 0.10232081399493703, 0.10611031453681062, 0.1027489451047476, 0.09210868750466615, 0.07492782219901652, 0.05353236819820311, 0.03542541633577168, 0.03933323894008774, 0.06270038799326437, 0.08932745321502307, 0.11340483041158125, 0.13266254812511455, 0.1459133453985276, 0.1525066589085052, 0.1521692896083444, 0.1449803354987343, 0.13145344721994037, 0.11279599511002215, 0.09159864106478845, 0.07355691029259237, 0.06896633966300512, 0.08359434759486732, 0.11016082666663302, 0.1406821019311761, 0.17117416060445154, 0.14855801270971222, 0.1456224162268725, 0.1480338412398998, 0.15328958820856428, 0.15853128893601995, 0.16140926346428514, 0.16035715328083872, 0.15453923311835846, 0.14371551456405646, 0.12812531802987187, 0.10841519876739372, 0.08561636792967618, 0.06117637768242537, 0.037068861971884706, 0.016325633366414773, 0.009267610244138542, 0.017173099012624007, 0.022467480374239023, 0.024111674310358256, 0.024177526287531254, 0.02853910736979532, 0.040966436390192255, 0.0582128326834258, 0.07595999306993556, 0.09102317112094495, 0.10114109985464467, 0.10478269921920712, 0.10107165703984604, 0.08978160816643517, 0.07142881844111035, 0.04772509561633735, 0.025089927712791886, 0.030762031001900482, 0.05849618705053634, 0.08726733596673227, 0.11261134687335944, 0.13277289391938482, 0.14677048045315516, 0.15406682091668958, 0.15447809905748988, 0.14817955745393024, 0.13581067584458018, 0.11875431191414546, 0.09978778256726006, 0.08434547645414395, 0.08074313294811437, 0.0934000998508713, 0.11734204736094453, 0.14585351532335364, 0.17494018231169609, 0.15813182985255766, 0.15508925575817517, 0.15674514327540545, 0.1609055691916762, 0.16501981702001858, 0.16691436555677278, 0.16507981387922505, 0.15866942228042719, 0.14740292775769379, 0.131472697013793, 0.11148570920746714, 0.08845219484055197, 0.06382906982299773, 0.03965234499153942, 0.019138511297802484, 0.01122937653028644, 0.017860158215882493, 0.023265718819957745, 0.024982576161999077, 0.024508422008642488, 0.02772201719235189, 0.039506685135444794, 0.05673157124728171, 0.07466326862131337, 0.08991383345203362, 0.10013972008397877, 0.10376901398039245, 0.09988981808219628, 0.08821385386529616, 0.06909816523489262, 0.043698388559317396, 0.01572431810570591, 0.02437990999996494, 0.056121049782674334, 0.08640681070483004, 0.11264559599488987, 0.13349003534268164, 0.14810611484209998, 0.15604155594469965, 0.1571866670356949, 0.15180160099460388, 0.1406353128809508, 0.12520506151849514, 0.10836680221435879, 0.09516044291328941, 0.09236696452642117, 0.10348923493075056, 0.12508202707376895, 0.15159430725347675, 0.17919480264500187, 0.16743944467377825, 0.16429074898057117, 0.16526745324447278, 0.16843078989432295, 0.17149665329374622, 0.17245896444013994, 0.16987425873967457, 0.16289766543306256, 0.15122019955652874, 0.13499651565520154, 0.11480044974897947, 0.09162261590462616, 0.06691837179490766, 0.042735518147752574, 0.02222227415870282, 0.012744858689087403, 0.017788390419430807, 0.023301364514841955, 0.025115593543148074, 0.02406434243348501, 0.026193185484499525, 0.037615409064927885, 0.05507914814611985, 0.07336411733491105, 0.08892395568501174, 0.09937309772713633, 0.10312908758610981, 0.09927581667368236, 0.08751281059131383, 0.06815049834062673, 0.04214000050457968, 0.011148437774370771, 0.022533127630518315, 0.05594910236762495, 0.08686552727468456, 0.11356520619937331, 0.13484747204540595, 0.14993963747840405, 0.15843794992278468, 0.160287448697729, 0.15581816947896635, 0.14586758980546258, 0.13204378690363056, 0.11719457620840391, 0.10591527844963386, 0.10379940121131168, 0.11370342577495678, 0.13321761559850792, 0.15779379218586637, 0.18386921261375963, 0.1764691783338955, 0.17321760819513385, 0.17358293333795244, 0.1758396936220875, 0.1779355040283822, 0.17802140149283488, 0.17472539021167965, 0.16721486894360485, 0.1551620663569642, 0.13869155199305006, 0.11834791227061346, 0.09509891317575762, 0.07037897584725882, 0.046184771187789575, 0.02540159849317532, 0.013854099197565037, 0.016895980786037438, 0.022541970272020692, 0.024498346964110893, 0.022819923262856392, 0.023903921596956618, 0.035330708360614194, 0.053333258593637266, 0.07213935191287092, 0.08812137996348503, 0.09890157690894363, 0.10291997634374336, 0.09928995383947584, 0.08775476856811595, 0.06871553924800322, 0.043437856110877644, 0.01648513888536587, 0.026415380227427575, 0.05809634633106263, 0.08868375463033293, 0.11539259980897125, 0.1368588603741197, 0.1522771471903334, 0.16125300186977573, 0.16376474932891044, 0.16019493522563621, 0.15144629801520976, 0.13917623392579626, 0.12616067970097047, 0.11654881141494987, 0.11501019099145776, 0.12392973886077849, 0.14161339186689303, 0.16434893643116752, 0.18889467855233252, 0.1852124400544273, 0.1818630232152628, 0.1816777585810585, 0.18311141866175715, 0.1843137457170021, 0.18358192376077279, 0.17961827862931484, 0.1716105817858392, 0.15922051709828672, 0.14254854118942203, 0.12211164044308559, 0.0988482417934543, 0.0741488972738083, 0.049901832837420605, 0.028621924975066222, 0.014689085688120565, 0.015140187196246407, 0.020984720051423572, 0.023158113070828604, 0.02078513143780927, 0.020836877804936788, 0.03276061195536475, 0.05161731631383248, 0.07108880023332265, 0.08758405405670917, 0.09878738380498961, 0.10319309941124027, 0.0999758864321981, 0.08897528855721756, 0.070805446541041, 0.047423395884855585, 0.026371718811091682, 0.034212129639922276, 0.06237554892822388, 0.09181768380950459, 0.11811411578400398, 0.13951800867378997, 0.15511187255199765, 0.1644744294521023, 0.16759601950127415, 0.16489348105390478, 0.15731123864462757, 0.14651933228552297, 0.13517859188407846, 0.1270158970881752, 0.12597493503908425, 0.13408589303951798, 0.15015872783788958, 0.1711665605059383, 0.19420467346173412, 0.19366330059357909, 0.1902223915307678, 0.18954148132747145, 0.19022912558424024, 0.19061208769284146, 0.18912269730416698, 0.18453841543268806, 0.17607344150455895, 0.16338551187370237, 0.14655541620185064, 0.12607250448819837, 0.10283784771774872, 0.07817650709558452, 0.05382784616052982, 0.031907329902583804, 0.015494424727151908, 0.012504714418535925, 0.018674365303265914, 0.021183486106905475, 0.018024691929682205, 0.01701736048445802, 0.030116570090339953, 0.05010563822895266, 0.07033341586166697, 0.08739713262454567, 0.09909171857551335, 0.103991284699282, 0.101357377320792, 0.0911656956024149, 0.07431668150563693, 0.05351812872366697, 0.03736436549566422, 0.04389305675653759, 0.0684008082636171, 0.09615315521578703, 0.12168357452700702, 0.14280046861301451, 0.15842533062702385, 0.1680818553119283, 0.171753287990331, 0.16987306310533162, 0.16340495154798984, 0.15400103402733967, 0.14418021778199908, 0.1372822491902475, 0.136673823308914, 0.14411079749680544, 0.15876404799463936, 0.1781641874673798, 0.19973640230076342, 0.20181813773767435, 0.198293072911281, 0.1971665177047432, 0.19717942601317942, 0.1968142426956413, 0.1946277778181896, 0.1894719237717014, 0.18059159666924612, 0.16764568305825286, 0.15069847652760301, 0.1302106600275821, 0.10703813088309493, 0.08242384846698746, 0.057939138162208526, 0.035331211177989076, 0.016622249574042087, 0.00902036399612811, 0.01574816577067776, 0.018771898460260308, 0.014715044070462665, 0.012557456119550935, 0.02775849205068681, 0.04902086053478827, 0.07000916735546361, 0.08764818321930035, 0.09987117255120681, 0.105346119966528, 0.10343702710892297, 0.09427681362414958, 0.07906447753134523, 0.061078350891076195, 0.048680605297071515, 0.054426101965079576, 0.07573919330944638, 0.10153089244423559, 0.12602919239832455, 0.14666639419936822, 0.16218905403842987, 0.17204824276716574, 0.1762046127178099, 0.17509211212594303, 0.1696738184540573, 0.16155953809881796, 0.15311169670556676, 0.1473213963743794, 0.14709085369773842, 0.15395844174844267, 0.16735718391616206, 0.1852699911965055, 0.20543178666868087, 0.20967533398327412, 0.20607416477415053, 0.20454772426849763, 0.20395189626285642, 0.2029066145886211, 0.20008305058757747, 0.19440572597761294, 0.1851530857949397, 0.17198897171573063, 0.15496339605049847, 0.13450704837106522, 0.11142444854345174, 0.08686695362151133, 0.06223919673104408, 0.03899257640698918, 0.01846096896228498, 0.004898642061025424, 0.012568975262310838, 0.01633375260862177, 0.011333816875959845, 0.007893902742682543, 0.02622355799577379, 0.04861661341560004, 0.07025602346358031, 0.0884207626111159, 0.10117387292797944, 0.10727601639850312, 0.10619721317342885, 0.09822841336767024, 0.08482895360734195, 0.06958934984069787, 0.060073696752900564, 0.06533913815226658, 0.08400775514972922, 0.10777300518291384, 0.13106205920124198, 0.15106415948805937, 0.16636666293833574, 0.17634144300507912, 0.18091545321945401, 0.18050944038900682, 0.1760686701509194, 0.16914224753195878, 0.16193026038323982, 0.15711278069578036, 0.15721329238067178, 0.16359387565100833, 0.17588018421131005, 0.19242221015149535, 0.21123800624448016, 0.21723501376481705, 0.21356629591540796, 0.21168204303731117, 0.2105386615250682, 0.20887800767690323, 0.20547614869354258, 0.19932766847298578, 0.18974615870624567, 0.1764031663722375, 0.15933601637562428, 0.13894438751934146, 0.11597777177885699, 0.0914940952564334, 0.06674940536701676, 0.04299479588099723, 0.021305039247457275, 0.002856276474562131, 0.010118764468277166, 0.014667188193081776, 0.009228941488045355, 0.005436470014226469, 0.026146954550411286, 0.04914058626034999, 0.0712027908729312, 0.0897871600603081, 0.10303591366443479, 0.10978529325770373, 0.10960293052452777, 0.10292117064813135, 0.09139247494999338, 0.0786898361169361, 0.07142998350568361, 0.07639426431197609, 0.09290383033894162, 0.11470353121992319, 0.13668443788925902, 0.15593419368900666, 0.17091605308711508, 0.18092573007530627, 0.18584989782616418, 0.18608515909324655, 0.18254502833981343, 0.17670466431773157, 0.1706018872905768, 0.16664050035080735, 0.16703126499867582, 0.17299049765955937, 0.18428666478833577, 0.1995682876534926, 0.21710770090007528];\n",
       "const xvar = \"lr\";\n",
       "const yvar = \"momentum\";\n",
       "const x_is_log = true;\n",
       "const y_is_log = false;\n",
       "\n",
       "const GREEN_SCALE = [[247, 252, 253], [229, 245, 249], [204, 236, 230], [153, 216, 201], [102, 194, 164], [65, 174, 118], [35, 139, 69], [0, 109, 44], [0, 68, 27]];\n",
       "const GREEN_PINK_SCALE = [[142, 1, 82], [197, 27, 125], [222, 119, 174], [241, 182, 218], [253, 224, 239], [247, 247, 247], [230, 245, 208], [184, 225, 134], [127, 188, 65], [77, 146, 33], [39, 100, 25]];\n",
       "const BLUE_SCALE = [[255, 247, 251], [236, 231, 242], [208, 209, 230], [166, 189, 219], [116, 169, 207], [54, 144, 192], [5, 112, 176], [3, 78, 123]];\n",
       "\n",
       "// format data\n",
       "const res = relativize_data(f, sd, rel, arm_data, metric);\n",
       "const f_final = res[0];\n",
       "const sd_final = res[1];\n",
       "\n",
       "// calculate max of abs(outcome), used for colorscale\n",
       "const f_absmax = Math.max(Math.abs(Math.min(...f_final)), Math.max(...f_final));\n",
       "\n",
       "// transform to nested array\n",
       "var f_plt = [];\n",
       "while(f_final.length) f_plt.push(f_final.splice(0, density));\n",
       "var sd_plt = [];\n",
       "while(sd_final.length) sd_plt.push(sd_final.splice(0, density));\n",
       "\n",
       "// create traces\n",
       "const CONTOUR_CONFIG = {\n",
       "  autocolorscale: false,\n",
       "  autocontour: true,\n",
       "  contours: {\n",
       "    coloring: 'heatmap',\n",
       "  },\n",
       "  hoverinfo: 'x+y+z',\n",
       "  ncontours: density / 2,\n",
       "  type: 'contour',\n",
       "  x: grid_x,\n",
       "  y: grid_y,\n",
       "};\n",
       "\n",
       "let f_scale;\n",
       "if (rel === true) {\n",
       "  f_scale = lower_is_better === true\n",
       "    ? GREEN_PINK_SCALE.reverse()\n",
       "    : GREEN_PINK_SCALE;\n",
       "} else {\n",
       "  f_scale = GREEN_SCALE;\n",
       "}\n",
       "\n",
       "const f_trace = {\n",
       "  colorbar: {\n",
       "    x: 0.45,\n",
       "    y: 0.5,\n",
       "    ticksuffix: rel === true ? '%' : '',\n",
       "    tickfont: {\n",
       "      size: 8,\n",
       "    },\n",
       "  },\n",
       "  colorscale: f_scale.map(\n",
       "    (v, i) => [i / (f_scale.length - 1), rgb(v)]\n",
       "  ),\n",
       "  xaxis: 'x',\n",
       "  yaxis: 'y',\n",
       "  z: f_plt,\n",
       "  // zmax and zmin are ignored if zauto is true\n",
       "  zauto: !rel,\n",
       "  zmax: f_absmax,\n",
       "  zmin: -f_absmax,\n",
       "};\n",
       "\n",
       "const sd_trace = {\n",
       "  colorbar: {\n",
       "      x: 1,\n",
       "      y: 0.5,\n",
       "      ticksuffix: rel === true ? '%' : '',\n",
       "      tickfont: {\n",
       "        size: 8,\n",
       "      },\n",
       "  },\n",
       "  colorscale: BLUE_SCALE.map(\n",
       "    (v, i) => [i / (BLUE_SCALE.length - 1), rgb(v)]\n",
       "  ),\n",
       "  xaxis: 'x2',\n",
       "  yaxis: 'y2',\n",
       "  z: sd_plt,\n",
       "};\n",
       "\n",
       "Object.keys(CONTOUR_CONFIG).forEach(key => {\n",
       "  f_trace[key] = CONTOUR_CONFIG[key];\n",
       "  sd_trace[key] = CONTOUR_CONFIG[key];\n",
       "});\n",
       "\n",
       "// get in-sample arms\n",
       "const arm_x = [];\n",
       "const arm_y = [];\n",
       "const arm_text = [];\n",
       "\n",
       "Object.keys(arm_data['in_sample']).forEach(arm_name => {\n",
       "  arm_x.push(arm_data['in_sample'][arm_name]['parameters'][xvar]);\n",
       "  arm_y.push(arm_data['in_sample'][arm_name]['parameters'][yvar]);\n",
       "  arm_text.push(arm_name);\n",
       "});\n",
       "\n",
       "// configs for in-sample arms\n",
       "const base_in_sample_arm_config = {\n",
       "  hoverinfo: 'text',\n",
       "  legendgroup: 'In-sample',\n",
       "  marker: {color: 'black', symbol: 1, opacity: 0.5},\n",
       "  mode: 'markers',\n",
       "  name: 'In-sample',\n",
       "  text: arm_text,\n",
       "  type: 'scatter',\n",
       "  x: arm_x,\n",
       "  y: arm_y,\n",
       "};\n",
       "\n",
       "const f_in_sample_arm_trace = {\n",
       "  xaxis: 'x',\n",
       "  yaxis: 'y',\n",
       "};\n",
       "\n",
       "const sd_in_sample_arm_trace = {\n",
       "  showlegend: false,\n",
       "  xaxis: 'x2',\n",
       "  yaxis: 'y2',\n",
       "};\n",
       "\n",
       "Object.keys(base_in_sample_arm_config).forEach(key => {\n",
       "  f_in_sample_arm_trace[key] = base_in_sample_arm_config[key];\n",
       "  sd_in_sample_arm_trace[key] = base_in_sample_arm_config[key];\n",
       "});\n",
       "\n",
       "const traces = [\n",
       "  f_trace,\n",
       "  sd_trace,\n",
       "  f_in_sample_arm_trace,\n",
       "  sd_in_sample_arm_trace,\n",
       "];\n",
       "\n",
       "// start symbol at 2 for candidate markers\n",
       "let i = 2;\n",
       "\n",
       "// iterate over out-of-sample arms\n",
       "Object.keys(arm_data['out_of_sample']).forEach(generator_run_name => {\n",
       "  const ax = [];\n",
       "  const ay = [];\n",
       "  const atext = [];\n",
       "\n",
       "  Object.keys(arm_data['out_of_sample'][generator_run_name]).forEach(arm_name => {\n",
       "    ax.push(\n",
       "      arm_data['out_of_sample'][generator_run_name][arm_name]['parameters'][xvar]\n",
       "    );\n",
       "    ay.push(\n",
       "      arm_data['out_of_sample'][generator_run_name][arm_name]['parameters'][yvar]\n",
       "    );\n",
       "    atext.push('<em>Candidate ' + arm_name + '</em>');\n",
       "  });\n",
       "\n",
       "  traces.push({\n",
       "    hoverinfo: 'text',\n",
       "    legendgroup: generator_run_name,\n",
       "    marker: {color: 'black', symbol: i, opacity: 0.5},\n",
       "    mode: 'markers',\n",
       "    name: generator_run_name,\n",
       "    text: atext,\n",
       "    type: 'scatter',\n",
       "    xaxis: 'x',\n",
       "    x: ax,\n",
       "    yaxis: 'y',\n",
       "    y: ay,\n",
       "  });\n",
       "  traces.push({\n",
       "    hoverinfo: 'text',\n",
       "    legendgroup: generator_run_name,\n",
       "    marker: {color: 'black', symbol: i, opacity: 0.5},\n",
       "    mode: 'markers',\n",
       "    name: 'In-sample',\n",
       "    showlegend: false,\n",
       "    text: atext,\n",
       "    type: 'scatter',\n",
       "    x: ax,\n",
       "    xaxis: 'x2',\n",
       "    y: ay,\n",
       "    yaxis: 'y2',\n",
       "  });\n",
       "  i += 1;\n",
       "});\n",
       "\n",
       "// layout\n",
       "const xrange = axis_range(grid_x, x_is_log);\n",
       "const yrange = axis_range(grid_y, y_is_log);\n",
       "\n",
       "const xtype = x_is_log ? 'log' : 'linear';\n",
       "const ytype = y_is_log ? 'log' : 'linear';\n",
       "\n",
       "const layout = {\n",
       "  autosize: false,\n",
       "    margin: {\n",
       "      l: 35,\n",
       "      r: 35,\n",
       "      t: 35,\n",
       "      b: 100,\n",
       "      pad: 0,\n",
       "  },\n",
       "  annotations: [\n",
       "    {\n",
       "      font: {size: 14},\n",
       "      showarrow: false,\n",
       "      text: 'Mean',\n",
       "      x: 0.25,\n",
       "      xanchor: 'center',\n",
       "      xref: 'paper',\n",
       "      y: 1,\n",
       "      yanchor: 'bottom',\n",
       "      yref: 'paper',\n",
       "    },\n",
       "    {\n",
       "      font: {size: 14},\n",
       "      showarrow: false,\n",
       "      text: 'Standard Error',\n",
       "      x: 0.8,\n",
       "      xanchor: 'center',\n",
       "      xref: 'paper',\n",
       "      y: 1,\n",
       "      yanchor: 'bottom',\n",
       "      yref: 'paper',\n",
       "    },\n",
       "  ],\n",
       "  hovermode: 'closest',\n",
       "  legend: {orientation: 'h', x: 0, y: -0.25},\n",
       "  height: 450,\n",
       "  width: 950,\n",
       "  xaxis: {\n",
       "    anchor: 'y',\n",
       "    autorange: false,\n",
       "    domain: [0.05, 0.45],\n",
       "    exponentformat: 'e',\n",
       "    range: xrange,\n",
       "    tickfont: {size: 11},\n",
       "    tickmode: 'auto',\n",
       "    title: xvar,\n",
       "    type: xtype,\n",
       "  },\n",
       "  xaxis2: {\n",
       "    anchor: 'y2',\n",
       "    autorange: false,\n",
       "    domain: [0.60, 1],\n",
       "    exponentformat: 'e',\n",
       "    range: xrange,\n",
       "    tickfont: {size: 11},\n",
       "    tickmode: 'auto',\n",
       "    title: xvar,\n",
       "    type: xtype,\n",
       "  },\n",
       "  yaxis: {\n",
       "    anchor: 'x',\n",
       "    autorange: false,\n",
       "    domain: [0, 1],\n",
       "    exponentformat: 'e',\n",
       "    range: yrange,\n",
       "    tickfont: {size: 11},\n",
       "    tickmode: 'auto',\n",
       "    title: yvar,\n",
       "    type: ytype,\n",
       "  },\n",
       "  yaxis2: {\n",
       "    anchor: 'x2',\n",
       "    autorange: false,\n",
       "    domain: [0, 1],\n",
       "    exponentformat: 'e',\n",
       "    range: yrange,\n",
       "    tickfont: {size: 11},\n",
       "    tickmode: 'auto',\n",
       "    type: ytype,\n",
       "  },\n",
       "};\n",
       "\n",
       "Plotly.newPlot(\"899c9fad5617455b94cc54fe88adfbe3\", traces, layout, {showLink: false});\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render(plot_contour(model=model, param_x='lr', param_y='momentum', metric_name='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"9bf37024078b424f8e48b382f3326e2b\" style=\"width: 100%;\" class=\"plotly-graph-div\"></div><script type='text/javascript'>/*\n",
       " * Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
       " */\n",
       "\n",
       "require(['plotly'], function(Plotly) {\n",
       "  window.PLOTLYENV = window.PLOTLYENV || {};\n",
       "  window.PLOTLYENV.BASE_URL = 'https://plot.ly';\n",
       "  /*\n",
       " * Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
       " */\n",
       "\n",
       "Plotly.newPlot(\n",
       "  \"9bf37024078b424f8e48b382f3326e2b\",\n",
       "  [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [11.583333333333332, 11.583333333333332, 26.0, 66.85, 66.85, 66.85, 73.31666666666666, 85.83333333333333, 89.03333333333333, 89.03333333333333, 89.43333333333334, 90.3, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75], \"legendgroup\": \"\", \"mode\": \"lines\", \"line\": {\"width\": 0}, \"showlegend\": false, \"hoverinfo\": \"none\"}, {\"type\": \"scatter\", \"name\": \"mean\", \"legendgroup\": \"mean\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [11.583333333333332, 11.583333333333332, 26.0, 66.85, 66.85, 66.85, 73.31666666666666, 85.83333333333333, 89.03333333333333, 89.03333333333333, 89.43333333333334, 90.3, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75], \"mode\": \"lines\", \"line\": {\"color\": \"rgba(128,177,211,1)\"}, \"fillcolor\": \"rgba(128,177,211,0.3)\", \"fill\": \"tonexty\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [11.583333333333332, 11.583333333333332, 26.0, 66.85, 66.85, 66.85, 73.31666666666666, 85.83333333333333, 89.03333333333333, 89.03333333333333, 89.43333333333334, 90.3, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75, 91.75], \"legendgroup\": \"\", \"mode\": \"lines\", \"line\": {\"width\": 0}, \"fillcolor\": \"rgba(128,177,211,0.3)\", \"fill\": \"tonexty\", \"showlegend\": false, \"hoverinfo\": \"none\"}],\n",
       "  {\"title\": \"Model performance vs. # of iterations\", \"showlegend\": true, \"yaxis\": {\"title\": \"Classification Accuracy, %\"}, \"xaxis\": {\"title\": \"Iteration\"}},\n",
       "  {\"showLink\": false}\n",
       ");\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `plot_single_method` expects a 2-d array of means, because it expects to average means from multiple \n",
    "# optimization runs, so we wrap out best objectives array in another array.\n",
    "best_objectives = np.array([[trial.objective_mean*100 for trial in experiment.trials.values()]])\n",
    "best_objective_plot = optimization_trace_single_method(\n",
    "    y=np.maximum.accumulate(best_objectives, axis=1),\n",
    "    title=\"Model performance vs. # of iterations\",\n",
    "    ylabel=\"Classification Accuracy, %\",\n",
    ")\n",
    "render(best_objective_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm(name='12_0', parameters={'lr': 0.00020134470130439496, 'momentum': 0.26958900203179714})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = experiment.fetch_data()\n",
    "df = data.df\n",
    "best_arm_name = df.arm_name[df['mean'] == df['mean'].max()].values[0]\n",
    "best_arm = experiment.arms_by_name[best_arm_name]\n",
    "best_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(\n",
    "    train_loader=train_loader, \n",
    "    parameters=best_arm.parameters,\n",
    "    dtype=dtype,\n",
    "    device=device,\n",
    ")\n",
    "test_accuracy = evaluate(\n",
    "    net=net,\n",
    "    data_loader=test_loader,\n",
    "    dtype=dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy (test set): 92.22%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification Accuracy (test set): {round(test_accuracy*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
